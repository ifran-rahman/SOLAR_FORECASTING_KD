# OPTIMIZING LIGHTWEIGHT PHOTOVOLTAIC FORECASTING MODELS: A DISTILLATION APPROACH

Abstract: Solar is the largest renewable energy source, yet its highly intermittent nature poses difficulties for efficient integration into grids. Hence, accurate solar forecasting is crucial for maximizing energy efficiency. Deep learning models have shown tremendous success in solar forecasting, nonetheless, they are typically larger and are more computationally complex. However, efficient and lightweight deep learning models are crucial for real-time prediction and deployment into resource-constrained devices. In this research, we propose a novel knowledge distillation method for enhancing lightweight time-series solar forecasting models. We evaluate the efficacy of the proposed approach by employing it on three popular sequence models-RNN, LSTM, and GRU. For each type of architecture, we distill the knowledge of a pre-trained highly accurate (teacher) model to its corresponding lightweight (student) model. Our extensive experiments, demonstrate that the proposed distillation method significantly reduces the errors of the efficient student models. The RNN student model (90\% fewer parameters than the teacher) improves with a 9.56\% reduction in NRMSE and a 19.53\% reduction in MAPE. Likewise, the LSTM and GRU student models also demonstrate notable improvement than before. These results suggest the potential of the proposed method in creating highly efficient solar forecasting models for real-time and edge-device deployable performance.
