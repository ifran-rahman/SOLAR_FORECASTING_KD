{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2KXKNGKw243x"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bRZKcqpK243y"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.layers import Dense, InputLayer, LSTM, Dropout, Bidirectional, SimpleRNN, GRU\n",
        "\n",
        "# from keras import ops\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bqALN4gU243z"
      },
      "outputs": [],
      "source": [
        "DC_POWER_INDEX = 0\n",
        "LEARNING_RATE = 0.001\n",
        "RANDOM_STATE = 44\n",
        "START_TIME = '2020-06-07 00:30:00'\n",
        "END_TIME = '2020-06-07 04:00:00'\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "def fix_randomness():\n",
        "    tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "    from numpy.random import seed\n",
        "    seed(RANDOM_STATE)\n",
        "    keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "fix_randomness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MULTIVARIATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 500\n",
        "MULTIV_TRAINING_WINDOW = 40\n",
        "lead_time = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating the model input for multivariate forecasting\n",
        "def df_to_model_input2(df_np, col_index, window_size):\n",
        "    df_np = df_np.to_numpy()\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(df_np) - window_size - lead_time):\n",
        "        row = [r for r in df_np[i:i+window_size]]\n",
        "        x.append(row)\n",
        "\n",
        "        label = df_np[i+lead_time+window_size][col_index]\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KVZSHLEo_2v6"
      },
      "outputs": [],
      "source": [
        "multiv_teacher_path = 'models/girasol/multiv_teacher_model.keras'\n",
        "multiv_student_path = 'models/girasol/multiv_student_model.keras'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv('/.../girasol_met/train.csv')\n",
        "test = pd.read_csv('/.../girasol_met/val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUMBER_OF_FEATURES = len(train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)\n",
        "test = pd.DataFrame(scaler.transform(test), columns=test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_train_test_val(x, y):\n",
        "    return x[:train_len], y[:train_len], x[train_len:], y[train_len:]\n",
        "\n",
        "x, y = df_to_model_input2(train, 7, MULTIV_TRAINING_WINDOW)\n",
        "\n",
        "ds_len = len(y)\n",
        "train_len = int(0.8*ds_len)\n",
        "\n",
        "x_train, y_train, x_val, y_val = get_train_test_val(x, y)\n",
        "x_test, y_test = df_to_model_input2(test, 7, MULTIV_TRAINING_WINDOW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((25163, 40, 8), (25163,))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape,  y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "teacher_hidden_layer_units, teacher_dense_params = 64, 8\n",
        "student_hidden_layer_units, student_dense_params = 16, 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "def calculate_mape(scaler, y_pred_scaled, target_column_index=-1):\n",
        "\n",
        "    # Create dummy arrays to match the scaler's expected input shape\n",
        "    dummy_data_pred = np.zeros((y_pred_scaled.shape[0], NUMBER_OF_FEATURES))\n",
        "    dummy_data_test = np.zeros((y_test.shape[0], NUMBER_OF_FEATURES))\n",
        "\n",
        "    # Insert the predicted values and y_test into the correct column\n",
        "    dummy_data_pred[:, target_column_index] = y_pred_scaled[:, 0]\n",
        "    dummy_data_test[:, target_column_index] = y_test[:] # it kept that way to be able to modify if needed\n",
        "\n",
        "    # Perform inverse transform to get the unscaled predictions and y_test\n",
        "    unscaled_predictions = scaler.inverse_transform(dummy_data_pred)[:, target_column_index]\n",
        "    y_test_unscaled = scaler.inverse_transform(dummy_data_test)[:, target_column_index]\n",
        "\n",
        "\n",
        "\n",
        "    mape = mean_absolute_percentage_error(y_test_unscaled, unscaled_predictions)*100\n",
        "    return mape\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate NMSE, NRMSE, and NMAE normalized by the average of true values.\n",
        "    \n",
        "    Parameters:\n",
        "        y_true (array-like): True values.\n",
        "        y_pred (array-like): Predicted values.\n",
        "        \n",
        "    Returns:\n",
        "        dict: A dictionary containing NMSE, NRMSE, and NMAE.\n",
        "    \"\"\"\n",
        "    # Convert inputs to numpy arrays for consistency\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    \n",
        "    # Mean Squared Error (MSE) and Mean Absolute Error (MAE) using sklearn\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "    mape = calculate_mape(scaler=scaler, y_pred_scaled=y_pred)\n",
        "    # Variance and mean of true values\n",
        "    avg_true = np.mean(y_true)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    nrmse = np.sqrt(mse) / avg_true\n",
        "    nmae = mae / avg_true\n",
        "\n",
        "    print(f\"NRMSE (Normalized Root Mean Squared Error): {nrmse:.4f}\")\n",
        "    print(f\"NMAE (Normalized Mean Absolute Error): {nmae:.4f}\")\n",
        "    print(f\"MAPE (Mean Absolute Percentage Error): {mape:.4f}\") \n",
        "    \n",
        "    # Return metrics as a dictionary\n",
        "    return nrmse, nmae, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - loss: 0.1196 - mean_squared_error: 0.1195 - val_loss: 0.0189 - val_mean_squared_error: 0.0177\n",
            "Epoch 2/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0240 - mean_squared_error: 0.0240 - val_loss: 0.0115 - val_mean_squared_error: 0.0111\n",
            "Epoch 3/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0162 - mean_squared_error: 0.0162 - val_loss: 0.0075 - val_mean_squared_error: 0.0077\n",
            "Epoch 4/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0136 - mean_squared_error: 0.0136 - val_loss: 0.0080 - val_mean_squared_error: 0.0081\n",
            "Epoch 5/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0069 - val_mean_squared_error: 0.0070\n",
            "Epoch 6/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0070 - val_mean_squared_error: 0.0071\n",
            "Epoch 7/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0100 - mean_squared_error: 0.0100 - val_loss: 0.0060 - val_mean_squared_error: 0.0062\n",
            "Epoch 8/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0049 - val_mean_squared_error: 0.0053\n",
            "Epoch 9/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0056 - val_mean_squared_error: 0.0059\n",
            "Epoch 10/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0050 - val_mean_squared_error: 0.0053\n",
            "Epoch 11/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0082 - mean_squared_error: 0.0082 - val_loss: 0.0050 - val_mean_squared_error: 0.0054\n",
            "Epoch 12/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - val_loss: 0.0050 - val_mean_squared_error: 0.0053\n",
            "Epoch 13/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0047 - val_mean_squared_error: 0.0052\n",
            "Epoch 14/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.0075 - mean_squared_error: 0.0075 - val_loss: 0.0047 - val_mean_squared_error: 0.0052\n",
            "Epoch 15/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0047 - val_mean_squared_error: 0.0051\n",
            "Epoch 16/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0047 - val_mean_squared_error: 0.0052\n",
            "Epoch 17/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0047 - val_mean_squared_error: 0.0051\n",
            "Epoch 18/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0047 - val_mean_squared_error: 0.0051\n",
            "Teacher Validation RMSE\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0023 - mean_squared_error: 0.0023    \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.004664697218686342, 0.004676278214901686]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "RANDOM_STATE = 44\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_STATE)\n",
        "keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "def run_teacher_multiv():\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(SimpleRNN(teacher_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(teacher_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Model checkpoint\n",
        "    model_file = multiv_teacher_path\n",
        "\n",
        "    cp = ModelCheckpoint(model_file, save_best_only=True)\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        loss=MeanSquaredError(),\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        metrics=[MeanSquaredError()]\n",
        "    )\n",
        "   \n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[cp, early_stopping]\n",
        "    )\n",
        "\n",
        "run_teacher_multiv()\n",
        "\n",
        "teacher = load_model(multiv_teacher_path)\n",
        "print(\"Teacher Validation RMSE\") \n",
        "teacher.evaluate(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1828\n",
            "NMAE (Normalized Mean Absolute Error): 0.1223\n",
            "MAPE (Mean Absolute Percentage Error): 25.1528\n",
            "Teacher Results: NRMSE = 0.1828, NMAE = 0.1223, MAPE = 25.1528\n"
          ]
        }
      ],
      "source": [
        "teacher = load_model(multiv_teacher_path)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred = teacher.predict(x_test)\n",
        "\n",
        "nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "# Store the results in a dictionary for the teacher\n",
        "teacher_results = {\n",
        "    \"NRMSE\": nrmse,\n",
        "    \"NMAE\": nmae,\n",
        "    \"MAPE\": mape\n",
        "}\n",
        "\n",
        "# Print the results in a single row\n",
        "print(f\"Teacher Results: NRMSE = {teacher_results['NRMSE']:.4f}, NMAE = {teacher_results['NMAE']:.4f}, MAPE = {teacher_results['MAPE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - loss: 0.2547 - mean_squared_error: 0.2546 - val_loss: 0.1441 - val_mean_squared_error: 0.1335\n",
            "Epoch 2/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0831 - mean_squared_error: 0.0831 - val_loss: 0.1005 - val_mean_squared_error: 0.0924\n",
            "Epoch 3/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0600 - mean_squared_error: 0.0600 - val_loss: 0.0745 - val_mean_squared_error: 0.0696\n",
            "Epoch 4/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0446 - mean_squared_error: 0.0446 - val_loss: 0.0517 - val_mean_squared_error: 0.0480\n",
            "Epoch 5/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0397 - val_mean_squared_error: 0.0367\n",
            "Epoch 6/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0272 - mean_squared_error: 0.0272 - val_loss: 0.0318 - val_mean_squared_error: 0.0293\n",
            "Epoch 7/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0224 - mean_squared_error: 0.0224 - val_loss: 0.0285 - val_mean_squared_error: 0.0263\n",
            "Epoch 8/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0191 - mean_squared_error: 0.0191 - val_loss: 0.0241 - val_mean_squared_error: 0.0224\n",
            "Epoch 9/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 0.0170 - mean_squared_error: 0.0170 - val_loss: 0.0210 - val_mean_squared_error: 0.0196\n",
            "Epoch 10/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0157 - mean_squared_error: 0.0157 - val_loss: 0.0171 - val_mean_squared_error: 0.0163\n",
            "Epoch 11/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0162 - val_mean_squared_error: 0.0155\n",
            "Epoch 12/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0163 - val_mean_squared_error: 0.0155\n",
            "Epoch 13/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0164 - val_mean_squared_error: 0.0155\n",
            "Epoch 14/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0145 - val_mean_squared_error: 0.0139\n",
            "Epoch 15/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0153 - val_mean_squared_error: 0.0146\n",
            "Epoch 16/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0148 - val_mean_squared_error: 0.0142\n",
            "Epoch 17/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0155 - val_mean_squared_error: 0.0148\n",
            "Epoch 18/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0156 - val_mean_squared_error: 0.0150\n",
            "Epoch 19/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0153 - val_mean_squared_error: 0.0146\n",
            "Student Validation RMSE\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - loss: 0.0142 - mean_squared_error: 0.0142\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.014528005383908749, 0.014525691978633404]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "RANDOM_STATE = 44\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_STATE)\n",
        "keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "def run_student_multiv():\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(SimpleRNN(student_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(student_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Model checkpoint\n",
        "    model_file = multiv_student_path\n",
        "\n",
        "    cp = ModelCheckpoint(model_file, save_best_only=True)\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        loss=MeanSquaredError(),\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        metrics=[MeanSquaredError()]\n",
        "    )\n",
        "   \n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=500,\n",
        "        callbacks=[cp, early_stopping]\n",
        "    )\n",
        "\n",
        "run_student_multiv()\n",
        "\n",
        "student = load_model(multiv_student_path)\n",
        "print(\"Student Validation RMSE\") \n",
        "student.evaluate(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 879us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.2913\n",
            "NMAE (Normalized Mean Absolute Error): 0.2352\n",
            "MAPE (Mean Absolute Percentage Error): 40.6118\n",
            "Student Results: NRMSE = 0.2913, NMAE = 0.2352, MAPE = 40.6118\n"
          ]
        }
      ],
      "source": [
        "student = load_model(multiv_student_path)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred = student.predict(x_test)\n",
        "\n",
        "nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "\n",
        "# Store the results in a dictionary\n",
        "student_results = {\n",
        "    \"NRMSE\": nrmse,\n",
        "    \"NMAE\": nmae,\n",
        "    \"MAPE\": mape\n",
        "}\n",
        "# Print the results in a single row\n",
        "print(f\"Student Results: NRMSE = {student_results['NRMSE']:.4f}, NMAE = {student_results['NMAE']:.4f}, MAPE = {student_results['MAPE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.saving import register_keras_serializable\n",
        "\n",
        "@register_keras_serializable()\n",
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "        self._loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        loss,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        loss_threshold,\n",
        "        alpha,\n",
        "        temperature\n",
        "\n",
        "    ):\n",
        "        \"\"\"Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super().compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "        self.loss_threshold = loss_threshold\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'student': self.student.to_json(),\n",
        "            'teacher': self.teacher.to_json()\n",
        "        }\n",
        "\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        student = tf.keras.models.model_from_json(config.pop('student'))\n",
        "        teacher = tf.keras.models.model_from_json(config.pop('teacher'))\n",
        "        return cls(student=student, teacher=teacher, **config)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            y_pred = self.student(x, training=True)\n",
        "            # Compute the loss value\n",
        "            loss = self.compute_loss(x, y, y_pred)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        # Return a dict mapping metric names to current value\n",
        "        results =  {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        results['total loss (train)'] = loss if isinstance(loss, float) else tf.reduce_mean(loss)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass to get student's predictions\n",
        "        y_pred = self.student(x, training=False)\n",
        "\n",
        "        # Compute the validation loss\n",
        "        val_loss = self.compute_loss(x, y, y_pred)\n",
        "\n",
        "        # Manually update the metrics for validation\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        # Collect results for all metrics\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        # Ensure 'val_loss' is properly reduced to a scalar and reported\n",
        "        results['total loss (val)'] = val_loss if isinstance(val_loss, float) else tf.reduce_mean(val_loss)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "\n",
        "    def compute_loss(\n",
        "        # self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "        self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "\n",
        "    ):\n",
        "\n",
        "        mse = MeanSquaredError()\n",
        "\n",
        "        # Compute predictions by the teacher model\n",
        "        teacher_pred = self.teacher(x, training=False)\n",
        "\n",
        "        # Compute the MSE loss between true labels and student predictions\n",
        "        student_loss = mse(y, y_pred)\n",
        "\n",
        "        # Teacher loss is the\n",
        "        temp = self.temperature\n",
        "        # loss = self.alpha * student_loss + (1 - self.alpha) * teacher_loss\n",
        "        loss = self.alpha * student_loss + (1 - self.alpha) * (mse(y_pred/temp, teacher_pred/temp)* (temp ** 2))\n",
        "\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.student(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_multiv_distillation(teacher, alpha, threshold, temperature, file_name, window_size):\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(SimpleRNN(student_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(student_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Create the distiller class\n",
        "    distiller = Distiller(student=model, teacher=teacher)\n",
        "\n",
        "    # Compile the distiller class\n",
        "    distiller.compile(\n",
        "    optimizer = Adam(learning_rate=LEARNING_RATE),\n",
        "    loss = MeanSquaredError(),\n",
        "    metrics = [RootMeanSquaredError()],\n",
        "    student_loss_fn = MeanSquaredError(),\n",
        "    distillation_loss_fn = distiller.compute_loss, #MeanSquaredError(),\n",
        "    loss_threshold = threshold,\n",
        "    alpha=alpha,\n",
        "    temperature=temperature\n",
        "    )\n",
        "\n",
        "    dummy_x = tf.random.normal([1, *((window_size, NUMBER_OF_FEATURES))])  # Replace `input_shape` with the actual shape of your input\n",
        "    _ = distiller(dummy_x) \n",
        "\n",
        "    d_check = ModelCheckpoint(file_name, monitor='root_mean_squared_error',save_best_only=True)\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    distiller.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=EPOCHS, callbacks=[d_check, early_stopping])\n",
        "\n",
        "    distilled_student = load_model(file_name)\n",
        "    # Make predictions using the distilled student model\n",
        "    y_pred = distilled_student.predict(x_val)\n",
        "\n",
        "    # Calculate the root mean squared error (RMSE)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print(\"Distilled Student RMSE:\", rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - root_mean_squared_error: 0.2488 - loss: 0.4731 - total loss (train): 0.0276 - val_loss: 0.5075 - val_total loss (val): 0.0026\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.1001 - loss: 0.5275 - total loss (train): 0.0054 - val_loss: 0.5321 - val_total loss (val): 0.0049\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0902 - loss: 0.5289 - total loss (train): 0.0039 - val_loss: 0.5109 - val_total loss (val): 0.0045\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0852 - loss: 0.5286 - total loss (train): 0.0033 - val_loss: 0.4998 - val_total loss (val): 0.0031\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0829 - loss: 0.5287 - total loss (train): 0.0030 - val_loss: 0.4913 - val_total loss (val): 0.0032\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0817 - loss: 0.5286 - total loss (train): 0.0028 - val_loss: 0.4786 - val_total loss (val): 0.0041\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0803 - loss: 0.5287 - total loss (train): 0.0026 - val_loss: 0.4756 - val_total loss (val): 0.0027\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0799 - loss: 0.5287 - total loss (train): 0.0026 - val_loss: 0.4674 - val_total loss (val): 0.0037\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0792 - loss: 0.5288 - total loss (train): 0.0025 - val_loss: 0.4528 - val_total loss (val): 0.0029\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0787 - loss: 0.5288 - total loss (train): 0.0024 - val_loss: 0.4415 - val_total loss (val): 0.0042\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0786 - loss: 0.5287 - total loss (train): 0.0024 - val_loss: 0.4328 - val_total loss (val): 0.0040\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0783 - loss: 0.5286 - total loss (train): 0.0024 - val_loss: 0.4316 - val_total loss (val): 0.0044\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0778 - loss: 0.5287 - total loss (train): 0.0024 - val_loss: 0.4225 - val_total loss (val): 0.0029\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0780 - loss: 0.5287 - total loss (train): 0.0023 - val_loss: 0.4235 - val_total loss (val): 0.0029\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0777 - loss: 0.5287 - total loss (train): 0.0023 - val_loss: 0.4069 - val_total loss (val): 0.0028\n",
            "Epoch 16/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0777 - loss: 0.5286 - total loss (train): 0.0023 - val_loss: 0.4029 - val_total loss (val): 0.0035\n",
            "Epoch 17/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0779 - loss: 0.5286 - total loss (train): 0.0023 - val_loss: 0.4029 - val_total loss (val): 0.0029\n",
            "Epoch 18/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0771 - loss: 0.5288 - total loss (train): 0.0022 - val_loss: 0.3938 - val_total loss (val): 0.0046\n",
            "Epoch 19/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0772 - loss: 0.5288 - total loss (train): 0.0022 - val_loss: 0.3786 - val_total loss (val): 0.0030\n",
            "Epoch 20/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0771 - loss: 0.5286 - total loss (train): 0.0022 - val_loss: 0.3771 - val_total loss (val): 0.0050\n",
            "Epoch 21/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0771 - loss: 0.5285 - total loss (train): 0.0022 - val_loss: 0.3741 - val_total loss (val): 0.0033\n",
            "Epoch 22/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0771 - loss: 0.5287 - total loss (train): 0.0022 - val_loss: 0.3672 - val_total loss (val): 0.0044\n",
            "Epoch 23/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0770 - loss: 0.5286 - total loss (train): 0.0022 - val_loss: 0.3671 - val_total loss (val): 0.0042\n",
            "Epoch 24/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0771 - loss: 0.5287 - total loss (train): 0.0022 - val_loss: 0.3609 - val_total loss (val): 0.0028\n",
            "Epoch 25/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0769 - loss: 0.5287 - total loss (train): 0.0022 - val_loss: 0.3564 - val_total loss (val): 0.0034\n",
            "Epoch 26/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0769 - loss: 0.5287 - total loss (train): 0.0022 - val_loss: 0.3529 - val_total loss (val): 0.0032\n",
            "Epoch 27/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0764 - loss: 0.5287 - total loss (train): 0.0021 - val_loss: 0.3416 - val_total loss (val): 0.0043\n",
            "Epoch 28/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0761 - loss: 0.5286 - total loss (train): 0.0021 - val_loss: 0.3429 - val_total loss (val): 0.0044\n",
            "Epoch 29/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0766 - loss: 0.5287 - total loss (train): 0.0021 - val_loss: 0.3360 - val_total loss (val): 0.0060\n",
            "Epoch 30/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0767 - loss: 0.5286 - total loss (train): 0.0021 - val_loss: 0.3313 - val_total loss (val): 0.0053\n",
            "Epoch 31/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0763 - loss: 0.5286 - total loss (train): 0.0021 - val_loss: 0.3349 - val_total loss (val): 0.0062\n",
            "Epoch 32/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0762 - loss: 0.5286 - total loss (train): 0.0021 - val_loss: 0.3328 - val_total loss (val): 0.0049\n",
            "Epoch 33/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0762 - loss: 0.5287 - total loss (train): 0.0021 - val_loss: 0.3274 - val_total loss (val): 0.0112\n",
            "Epoch 34/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0761 - loss: 0.5286 - total loss (train): 0.0021 - val_loss: 0.3184 - val_total loss (val): 0.0094\n",
            "Epoch 35/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0763 - loss: 0.5287 - total loss (train): 0.0021 - val_loss: 0.3247 - val_total loss (val): 0.0081\n",
            "Epoch 36/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0762 - loss: 0.5287 - total loss (train): 0.0021 - val_loss: 0.3216 - val_total loss (val): 0.0071\n",
            "Epoch 37/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0761 - loss: 0.5287 - total loss (train): 0.0021 - val_loss: 0.3176 - val_total loss (val): 0.0116\n",
            "Epoch 38/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0757 - loss: 0.5286 - total loss (train): 0.0021 - val_loss: 0.3152 - val_total loss (val): 0.0126\n",
            "Epoch 39/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0759 - loss: 0.5286 - total loss (train): 0.0021 - val_loss: 0.3094 - val_total loss (val): 0.0134\n",
            "Epoch 40/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0760 - loss: 0.5286 - total loss (train): 0.0021 - val_loss: 0.3116 - val_total loss (val): 0.0130\n",
            "Epoch 41/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0757 - loss: 0.5287 - total loss (train): 0.0020 - val_loss: 0.3131 - val_total loss (val): 0.0120\n",
            "Epoch 42/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0759 - loss: 0.5286 - total loss (train): 0.0020 - val_loss: 0.3130 - val_total loss (val): 0.0119\n",
            "Epoch 43/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0758 - loss: 0.5287 - total loss (train): 0.0020 - val_loss: 0.3104 - val_total loss (val): 0.0115\n",
            "Epoch 44/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0758 - loss: 0.5286 - total loss (train): 0.0020 - val_loss: 0.3116 - val_total loss (val): 0.0124\n",
            "\u001b[1m111/291\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 919us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "Distilled Student RMSE: 0.08920917190644247\n",
            "\u001b[1m126/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 801us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 741us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1957\n",
            "NMAE (Normalized Mean Absolute Error): 0.1490\n",
            "MAPE (Mean Absolute Percentage Error): 21.0848\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - root_mean_squared_error: 0.2485 - loss: 0.4724 - total loss (train): 0.0288 - val_loss: 0.5064 - val_total loss (val): 0.0034\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.1000 - loss: 0.5266 - total loss (train): 0.0066 - val_loss: 0.5319 - val_total loss (val): 0.0041\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0902 - loss: 0.5281 - total loss (train): 0.0051 - val_loss: 0.5116 - val_total loss (val): 0.0091\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0851 - loss: 0.5278 - total loss (train): 0.0044 - val_loss: 0.4997 - val_total loss (val): 0.0060\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0831 - loss: 0.5278 - total loss (train): 0.0041 - val_loss: 0.4894 - val_total loss (val): 0.0058\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0819 - loss: 0.5277 - total loss (train): 0.0040 - val_loss: 0.4783 - val_total loss (val): 0.0088\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0806 - loss: 0.5278 - total loss (train): 0.0038 - val_loss: 0.4829 - val_total loss (val): 0.0043\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0803 - loss: 0.5279 - total loss (train): 0.0037 - val_loss: 0.4737 - val_total loss (val): 0.0062\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0795 - loss: 0.5279 - total loss (train): 0.0036 - val_loss: 0.4640 - val_total loss (val): 0.0063\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0790 - loss: 0.5280 - total loss (train): 0.0036 - val_loss: 0.4517 - val_total loss (val): 0.0082\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0787 - loss: 0.5278 - total loss (train): 0.0035 - val_loss: 0.4406 - val_total loss (val): 0.0095\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0786 - loss: 0.5277 - total loss (train): 0.0035 - val_loss: 0.4408 - val_total loss (val): 0.0089\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0780 - loss: 0.5279 - total loss (train): 0.0035 - val_loss: 0.4346 - val_total loss (val): 0.0072\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0782 - loss: 0.5277 - total loss (train): 0.0035 - val_loss: 0.4307 - val_total loss (val): 0.0066\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0776 - loss: 0.5279 - total loss (train): 0.0034 - val_loss: 0.4203 - val_total loss (val): 0.0048\n",
            "Epoch 16/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0777 - loss: 0.5277 - total loss (train): 0.0034 - val_loss: 0.4169 - val_total loss (val): 0.0064\n",
            "Epoch 17/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0778 - loss: 0.5277 - total loss (train): 0.0034 - val_loss: 0.4164 - val_total loss (val): 0.0073\n",
            "Epoch 18/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0771 - loss: 0.5278 - total loss (train): 0.0034 - val_loss: 0.4197 - val_total loss (val): 0.0072\n",
            "Epoch 19/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0775 - loss: 0.5279 - total loss (train): 0.0034 - val_loss: 0.4084 - val_total loss (val): 0.0048\n",
            "Epoch 20/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0770 - loss: 0.5276 - total loss (train): 0.0033 - val_loss: 0.4127 - val_total loss (val): 0.0057\n",
            "Epoch 21/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0772 - loss: 0.5277 - total loss (train): 0.0034 - val_loss: 0.4100 - val_total loss (val): 0.0054\n",
            "Epoch 22/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0773 - loss: 0.5278 - total loss (train): 0.0034 - val_loss: 0.4071 - val_total loss (val): 0.0078\n",
            "Epoch 23/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0769 - loss: 0.5277 - total loss (train): 0.0033 - val_loss: 0.4129 - val_total loss (val): 0.0049\n",
            "Epoch 24/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0773 - loss: 0.5277 - total loss (train): 0.0033 - val_loss: 0.4148 - val_total loss (val): 0.0056\n",
            "Epoch 25/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0770 - loss: 0.5277 - total loss (train): 0.0033 - val_loss: 0.4068 - val_total loss (val): 0.0067\n",
            "Epoch 26/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0769 - loss: 0.5277 - total loss (train): 0.0033 - val_loss: 0.4146 - val_total loss (val): 0.0039\n",
            "Epoch 27/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0768 - loss: 0.5278 - total loss (train): 0.0033 - val_loss: 0.4098 - val_total loss (val): 0.0044\n",
            "Epoch 28/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0767 - loss: 0.5278 - total loss (train): 0.0033 - val_loss: 0.4063 - val_total loss (val): 0.0051\n",
            "Epoch 29/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0767 - loss: 0.5276 - total loss (train): 0.0033 - val_loss: 0.4099 - val_total loss (val): 0.0032\n",
            "Epoch 30/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0768 - loss: 0.5278 - total loss (train): 0.0033 - val_loss: 0.4032 - val_total loss (val): 0.0044\n",
            "Epoch 31/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0766 - loss: 0.5276 - total loss (train): 0.0033 - val_loss: 0.4068 - val_total loss (val): 0.0033\n",
            "Epoch 32/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0771 - loss: 0.5279 - total loss (train): 0.0033 - val_loss: 0.4050 - val_total loss (val): 0.0035\n",
            "Epoch 33/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0764 - loss: 0.5277 - total loss (train): 0.0033 - val_loss: 0.3943 - val_total loss (val): 0.0043\n",
            "Epoch 34/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0764 - loss: 0.5276 - total loss (train): 0.0033 - val_loss: 0.3977 - val_total loss (val): 0.0035\n",
            "Epoch 35/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0764 - loss: 0.5279 - total loss (train): 0.0032 - val_loss: 0.3906 - val_total loss (val): 0.0035\n",
            "Epoch 36/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0764 - loss: 0.5279 - total loss (train): 0.0032 - val_loss: 0.3919 - val_total loss (val): 0.0035\n",
            "Epoch 37/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0763 - loss: 0.5278 - total loss (train): 0.0032 - val_loss: 0.3805 - val_total loss (val): 0.0040\n",
            "Epoch 38/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0759 - loss: 0.5277 - total loss (train): 0.0032 - val_loss: 0.3806 - val_total loss (val): 0.0045\n",
            "Epoch 39/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0760 - loss: 0.5278 - total loss (train): 0.0032 - val_loss: 0.3790 - val_total loss (val): 0.0040\n",
            "Epoch 40/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0759 - loss: 0.5278 - total loss (train): 0.0032 - val_loss: 0.3772 - val_total loss (val): 0.0035\n",
            "Epoch 41/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0756 - loss: 0.5279 - total loss (train): 0.0032 - val_loss: 0.3751 - val_total loss (val): 0.0037\n",
            "Epoch 42/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - root_mean_squared_error: 0.0758 - loss: 0.5277 - total loss (train): 0.0032 - val_loss: 0.3751 - val_total loss (val): 0.0036\n",
            "Epoch 43/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - root_mean_squared_error: 0.0758 - loss: 0.5279 - total loss (train): 0.0032 - val_loss: 0.3712 - val_total loss (val): 0.0030\n",
            "Epoch 44/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0758 - loss: 0.5277 - total loss (train): 0.0032 - val_loss: 0.3707 - val_total loss (val): 0.0047\n",
            "Epoch 45/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0757 - loss: 0.5278 - total loss (train): 0.0032 - val_loss: 0.3656 - val_total loss (val): 0.0032\n",
            "Epoch 46/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0758 - loss: 0.5277 - total loss (train): 0.0031 - val_loss: 0.3670 - val_total loss (val): 0.0036\n",
            "Epoch 47/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0756 - loss: 0.5277 - total loss (train): 0.0032 - val_loss: 0.3698 - val_total loss (val): 0.0039\n",
            "Epoch 48/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0757 - loss: 0.5277 - total loss (train): 0.0032 - val_loss: 0.3669 - val_total loss (val): 0.0030\n",
            "Epoch 49/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0756 - loss: 0.5278 - total loss (train): 0.0032 - val_loss: 0.3656 - val_total loss (val): 0.0031\n",
            "Epoch 50/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0755 - loss: 0.5278 - total loss (train): 0.0031 - val_loss: 0.3628 - val_total loss (val): 0.0031\n",
            "Epoch 51/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0758 - loss: 0.5277 - total loss (train): 0.0031 - val_loss: 0.3633 - val_total loss (val): 0.0041\n",
            "Epoch 52/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0759 - loss: 0.5277 - total loss (train): 0.0032 - val_loss: 0.3641 - val_total loss (val): 0.0035\n",
            "Epoch 53/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0754 - loss: 0.5277 - total loss (train): 0.0031 - val_loss: 0.3632 - val_total loss (val): 0.0030\n",
            "Epoch 54/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0757 - loss: 0.5278 - total loss (train): 0.0031 - val_loss: 0.3604 - val_total loss (val): 0.0032\n",
            "Epoch 55/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0757 - loss: 0.5277 - total loss (train): 0.0031 - val_loss: 0.3612 - val_total loss (val): 0.0032\n",
            "Epoch 56/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0754 - loss: 0.5278 - total loss (train): 0.0031 - val_loss: 0.3581 - val_total loss (val): 0.0033\n",
            "Epoch 57/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - root_mean_squared_error: 0.0754 - loss: 0.5277 - total loss (train): 0.0031 - val_loss: 0.3545 - val_total loss (val): 0.0033\n",
            "Epoch 58/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0758 - loss: 0.5278 - total loss (train): 0.0031 - val_loss: 0.3585 - val_total loss (val): 0.0030\n",
            "Epoch 59/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0757 - loss: 0.5278 - total loss (train): 0.0031 - val_loss: 0.3619 - val_total loss (val): 0.0032\n",
            "Epoch 60/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0755 - loss: 0.5277 - total loss (train): 0.0031 - val_loss: 0.3589 - val_total loss (val): 0.0032\n",
            "Epoch 61/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0755 - loss: 0.5277 - total loss (train): 0.0031 - val_loss: 0.3602 - val_total loss (val): 0.0040\n",
            "Epoch 62/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0757 - loss: 0.5277 - total loss (train): 0.0031 - val_loss: 0.3602 - val_total loss (val): 0.0030\n",
            "\u001b[1m128/291\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 792us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step\n",
            "Distilled Student RMSE: 0.09060447726050369\n",
            "\u001b[1m123/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 833us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1980\n",
            "NMAE (Normalized Mean Absolute Error): 0.1510\n",
            "MAPE (Mean Absolute Percentage Error): 21.1167\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - root_mean_squared_error: 0.2478 - loss: 0.4719 - total loss (train): 0.0298 - val_loss: 0.5040 - val_total loss (val): 0.0056\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.1004 - loss: 0.5258 - total loss (train): 0.0077 - val_loss: 0.5380 - val_total loss (val): 0.0106\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0903 - loss: 0.5273 - total loss (train): 0.0062 - val_loss: 0.5089 - val_total loss (val): 0.0145\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0856 - loss: 0.5269 - total loss (train): 0.0056 - val_loss: 0.5029 - val_total loss (val): 0.0098\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0836 - loss: 0.5269 - total loss (train): 0.0053 - val_loss: 0.4904 - val_total loss (val): 0.0083\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0826 - loss: 0.5268 - total loss (train): 0.0051 - val_loss: 0.4807 - val_total loss (val): 0.0140\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0810 - loss: 0.5270 - total loss (train): 0.0049 - val_loss: 0.4765 - val_total loss (val): 0.0085\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0805 - loss: 0.5269 - total loss (train): 0.0049 - val_loss: 0.4747 - val_total loss (val): 0.0097\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0798 - loss: 0.5271 - total loss (train): 0.0048 - val_loss: 0.4679 - val_total loss (val): 0.0122\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0794 - loss: 0.5271 - total loss (train): 0.0047 - val_loss: 0.4577 - val_total loss (val): 0.0123\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0790 - loss: 0.5269 - total loss (train): 0.0046 - val_loss: 0.4488 - val_total loss (val): 0.0138\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0790 - loss: 0.5268 - total loss (train): 0.0046 - val_loss: 0.4515 - val_total loss (val): 0.0142\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0783 - loss: 0.5272 - total loss (train): 0.0046 - val_loss: 0.4463 - val_total loss (val): 0.0092\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - root_mean_squared_error: 0.0785 - loss: 0.5270 - total loss (train): 0.0046 - val_loss: 0.4354 - val_total loss (val): 0.0114\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - root_mean_squared_error: 0.0779 - loss: 0.5270 - total loss (train): 0.0045 - val_loss: 0.4283 - val_total loss (val): 0.0082\n",
            "Epoch 16/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - root_mean_squared_error: 0.0779 - loss: 0.5269 - total loss (train): 0.0045 - val_loss: 0.4287 - val_total loss (val): 0.0106\n",
            "Epoch 17/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - root_mean_squared_error: 0.0779 - loss: 0.5269 - total loss (train): 0.0045 - val_loss: 0.4276 - val_total loss (val): 0.0115\n",
            "Epoch 18/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - root_mean_squared_error: 0.0772 - loss: 0.5269 - total loss (train): 0.0044 - val_loss: 0.4250 - val_total loss (val): 0.0113\n",
            "Epoch 19/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - root_mean_squared_error: 0.0776 - loss: 0.5271 - total loss (train): 0.0045 - val_loss: 0.4178 - val_total loss (val): 0.0073\n",
            "Epoch 20/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - root_mean_squared_error: 0.0772 - loss: 0.5268 - total loss (train): 0.0044 - val_loss: 0.4258 - val_total loss (val): 0.0081\n",
            "Epoch 21/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - root_mean_squared_error: 0.0774 - loss: 0.5270 - total loss (train): 0.0044 - val_loss: 0.4190 - val_total loss (val): 0.0082\n",
            "Epoch 22/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - root_mean_squared_error: 0.0775 - loss: 0.5270 - total loss (train): 0.0045 - val_loss: 0.4220 - val_total loss (val): 0.0118\n",
            "Epoch 23/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - root_mean_squared_error: 0.0771 - loss: 0.5269 - total loss (train): 0.0044 - val_loss: 0.4238 - val_total loss (val): 0.0073\n",
            "Epoch 24/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - root_mean_squared_error: 0.0773 - loss: 0.5269 - total loss (train): 0.0044 - val_loss: 0.4259 - val_total loss (val): 0.0105\n",
            "\u001b[1m173/291\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 585us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step\n",
            "Distilled Student RMSE: 0.0892657663739947\n",
            "\u001b[1m170/787\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 596us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 623us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.2102\n",
            "NMAE (Normalized Mean Absolute Error): 0.1633\n",
            "MAPE (Mean Absolute Percentage Error): 27.5346\n"
          ]
        }
      ],
      "source": [
        "alphas = [0.3, 0.5, 0.7]\n",
        "temps = [5]\n",
        "threshold = 0\n",
        "\n",
        "# Initialize a 2D list to store RMSE values\n",
        "rmse_matrix = []\n",
        "\n",
        "# Iterate over alphas and temps\n",
        "for alpha in alphas:\n",
        "    row_rmse = []\n",
        "    for temp in temps:\n",
        "\n",
        "        RANDOM_STATE = 44\n",
        "        tf.random.set_seed(RANDOM_STATE)\n",
        "        from numpy.random import seed\n",
        "        seed(RANDOM_STATE)\n",
        "        keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "        multiv_distill_file_name = 'models/girasol/distils/multiv_distil_'+str(alpha)+'_'+str(temp)+'/multiv_distil.keras'\n",
        "        \n",
        "        run_multiv_distillation(teacher, alpha, threshold, temp,  multiv_distill_file_name, MULTIV_TRAINING_WINDOW)\n",
        "        \n",
        "        # Load the model\n",
        "        multiv_distill_file_name = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "        student_kd = load_model(multiv_distill_file_name)\n",
        "\n",
        "        # Make predictions on the scaled test set\n",
        "        y_pred = student_kd.predict(x_test)\n",
        "\n",
        "        nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "        \n",
        "        row_rmse.append(nrmse)\n",
        "\n",
        "    # Append the row of RMSE values to the matrix\n",
        "    rmse_matrix.append(row_rmse)\n",
        "\n",
        "# Convert the list to a NumPy array for plotting\n",
        "rmse_matrix = np.array(rmse_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m167/787\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 605us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 625us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1957\n",
            "NMAE (Normalized Mean Absolute Error): 0.1490\n",
            "MAPE (Mean Absolute Percentage Error): 21.0848\n",
            "Alpha: 0.3, Temp: 5, NRMSE: 0.1957, NMAE: 0.1490, MAPE: 21.0848\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Example inputs\n",
        "alphas = [0.3]\n",
        "temps = [5]\n",
        "threshold = 0\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "student_kd_results = []\n",
        "\n",
        "# Iterate over alphas and temps\n",
        "for alpha in alphas:\n",
        "    for temp in temps:\n",
        "        multiv_distill_file_name = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "        \n",
        "        # Load the model\n",
        "        student_kd = load_model(multiv_distill_file_name)\n",
        "\n",
        "        # Make predictions on the scaled test set\n",
        "        y_pred = student_kd.predict(x_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "        \n",
        "        # Add the results to the dictionary\n",
        "        student_kd_results.append({\n",
        "            \"alpha\": alpha,\n",
        "            \"temp\": temp,\n",
        "            \"NRMSE\": nrmse,\n",
        "            \"NMAE\": nmae,\n",
        "            \"MAPE\": mape\n",
        "        })\n",
        "\n",
        "# Print the results\n",
        "for result in student_kd_results:\n",
        "    print(f\"Alpha: {result['alpha']}, Temp: {result['temp']}, NRMSE: {result['NRMSE']:.4f}, \"\n",
        "          f\"NMAE: {result['NMAE']:.4f}, MAPE: {result['MAPE']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Efficiency Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,672</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn (\u001b[38;5;33mSimpleRNN\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,672\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m520\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">15,605</span> (60.96 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m15,605\u001b[0m (60.96 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,201</span> (20.32 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,201\u001b[0m (20.32 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,404</span> (40.64 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m10,404\u001b[0m (40.64 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of parameters: 5201\n",
            "Model size on disk: 91.61 KB\n"
          ]
        }
      ],
      "source": [
        "teacher = load_model(multiv_teacher_path)\n",
        "\n",
        "# 1. Print model summary (Layer details and parameter count)\n",
        "print(\"Model Summary:\")\n",
        "teacher.summary()\n",
        "\n",
        "# 2. Get the total number of parameters\n",
        "total_params = teacher.count_params()\n",
        "print(f'\\nTotal number of parameters: {total_params}')\n",
        "\n",
        "# 3. Get the size of the model file on disk\n",
        "model_size = os.path.getsize(multiv_teacher_path) / 1024  #a Convert from bytes to MB\n",
        "print(f'Model size on disk: {model_size:.2f} KB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ simple_rnn_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m400\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,637</span> (6.40 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,637\u001b[0m (6.40 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">545</span> (2.13 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m545\u001b[0m (2.13 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,092</span> (4.27 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,092\u001b[0m (4.27 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of parameters: 545\n",
            "Model size on disk: 37.05 KB\n"
          ]
        }
      ],
      "source": [
        "student = load_model(multiv_student_path)\n",
        "\n",
        "# 1. Print model summary (Layer details and parameter count)\n",
        "print(\"Model Summary:\")\n",
        "student.summary()\n",
        "\n",
        "# 2. Get the total number of parameters\n",
        "total_params = student.count_params()\n",
        "print(f'\\nTotal number of parameters: {total_params}')\n",
        "\n",
        "# 3. Get the size of the model file on disk\n",
        "model_size = os.path.getsize(multiv_student_path) / 1024  #a Convert from bytes to MB\n",
        "print(f'Model size on disk: {model_size:.2f} KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Error Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Results: NRMSE = 0.1828, NMAE = 0.1223, MAPE = 25.1528\n",
            "Student Results: NRMSE = 0.2913, NMAE = 0.2352, MAPE = 40.6118\n",
            "Student KD Results\n",
            "Alpha: 0.3, Temp: 5, NRMSE: 0.1957, NMAE: 0.1490, MAPE: 21.0848\n"
          ]
        }
      ],
      "source": [
        "# Print the results in a single row\n",
        "print(f\"Teacher Results: NRMSE = {teacher_results['NRMSE']:.4f}, NMAE = {teacher_results['NMAE']:.4f}, MAPE = {teacher_results['MAPE']:.4f}\")\n",
        "\n",
        "# Print the results in a single row\n",
        "print(f\"Student Results: NRMSE = {student_results['NRMSE']:.4f}, NMAE = {student_results['NMAE']:.4f}, MAPE = {student_results['MAPE']:.4f}\")\n",
        "\n",
        "print('Student KD Results')\n",
        "# Print the results\n",
        "for result in student_kd_results:\n",
        "    print(f\"Alpha: {result['alpha']}, Temp: {result['temp']}, NRMSE: {result['NRMSE']:.4f}, \"\n",
        "          f\"NMAE: {result['NMAE']:.4f}, MAPE: {result['MAPE']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m alphas \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.7\u001b[39m]\n\u001b[1;32m      4\u001b[0m temps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m]\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "alphas = [0.3, 0.5, 0.7]\n",
        "temps = [5]\n",
        "\n",
        "# Initialize a 2D list to store RMSE values\n",
        "rmse_matrix = []\n",
        "\n",
        "# Iterate over alphas and temps\n",
        "for alpha in alphas:\n",
        "    row_rmse = []\n",
        "    for temp in temps:\n",
        "        # Load the model\n",
        "        multiv_distill_file_name = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "        student_kd = load_model(multiv_distill_file_name)\n",
        "\n",
        "        # Make predictions on the scaled test set\n",
        "        y_pred = student_kd.predict(x_test)\n",
        "\n",
        "        nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "        \n",
        "        row_rmse.append(nrmse)\n",
        "\n",
        "    # Append the row of RMSE values to the matrix\n",
        "    rmse_matrix.append(row_rmse)\n",
        "\n",
        "# Convert the list to a NumPy array for plotting\n",
        "rmse_matrix = np.array(rmse_matrix)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(rmse_matrix, annot=True, fmt='.2f', cmap='viridis', xticklabels=temps, yticklabels=alphas)\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Alpha')\n",
        "plt.title('Distilled Models on Multivariate Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
