{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2KXKNGKw243x"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bRZKcqpK243y"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.layers import Dense, InputLayer, LSTM, Dropout, Bidirectional\n",
        "\n",
        "# from keras import ops\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bqALN4gU243z"
      },
      "outputs": [],
      "source": [
        "DC_POWER_INDEX = 0\n",
        "LEARNING_RATE = 0.001\n",
        "RANDOM_STATE = 44\n",
        "START_TIME = '2020-06-07 00:30:00'\n",
        "END_TIME = '2020-06-07 04:00:00'\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "def fix_randomness():\n",
        "    tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "    from numpy.random import seed\n",
        "    seed(RANDOM_STATE)\n",
        "    keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "fix_randomness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MULTIVARIATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 500\n",
        "MULTIV_TRAINING_WINDOW = 40\n",
        "lead_time = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating the model input for multivariate forecasting\n",
        "def df_to_model_input2(df_np, col_index, window_size):\n",
        "    df_np = df_np.to_numpy()\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(df_np) - window_size - lead_time):\n",
        "        row = [r for r in df_np[i:i+window_size]]\n",
        "        x.append(row)\n",
        "\n",
        "        label = df_np[i+lead_time+window_size][col_index]\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KVZSHLEo_2v6"
      },
      "outputs": [],
      "source": [
        "multiv_teacher_path = 'models/girasol/multiv_teacher_model.keras'\n",
        "multiv_student_path = 'models/girasol/multiv_student_model.keras'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv('/.../girasol_met/train.csv')\n",
        "test = pd.read_csv('/.../girasol_met/val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUMBER_OF_FEATURES = len(train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)\n",
        "test = pd.DataFrame(scaler.transform(test), columns=test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_train_test_val(x, y):\n",
        "    return x[:train_len], y[:train_len], x[train_len:], y[train_len:]\n",
        "\n",
        "x, y = df_to_model_input2(train, 7, MULTIV_TRAINING_WINDOW)\n",
        "\n",
        "ds_len = len(y)\n",
        "train_len = int(0.8*ds_len)\n",
        "\n",
        "x_train, y_train, x_val, y_val = get_train_test_val(x, y)\n",
        "x_test, y_test = df_to_model_input2(test, 7, MULTIV_TRAINING_WINDOW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((25163, 40, 8), (25163,))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape,  y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "teacher_hidden_layer_units, teacher_dense_params = 512, 8\n",
        "student_hidden_layer_units, student_dense_params = 16, 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "def calculate_mape(scaler, y_pred_scaled, target_column_index=-1):\n",
        "\n",
        "    # Create dummy arrays to match the scaler's expected input shape\n",
        "    dummy_data_pred = np.zeros((y_pred_scaled.shape[0], NUMBER_OF_FEATURES))\n",
        "    dummy_data_test = np.zeros((y_test.shape[0], NUMBER_OF_FEATURES))\n",
        "\n",
        "    # Insert the predicted values and y_test into the correct column\n",
        "    dummy_data_pred[:, target_column_index] = y_pred_scaled[:, 0]\n",
        "    dummy_data_test[:, target_column_index] = y_test[:] # it kept that way to be able to modify if needed\n",
        "\n",
        "    # Perform inverse transform to get the unscaled predictions and y_test\n",
        "    unscaled_predictions = scaler.inverse_transform(dummy_data_pred)[:, target_column_index]\n",
        "    y_test_unscaled = scaler.inverse_transform(dummy_data_test)[:, target_column_index]\n",
        "\n",
        "\n",
        "\n",
        "    mape = mean_absolute_percentage_error(y_test_unscaled, unscaled_predictions)*100\n",
        "    return mape\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate NMSE, NRMSE, and NMAE normalized by the average of true values.\n",
        "    \n",
        "    Parameters:\n",
        "        y_true (array-like): True values.\n",
        "        y_pred (array-like): Predicted values.\n",
        "        \n",
        "    Returns:\n",
        "        dict: A dictionary containing NMSE, NRMSE, and NMAE.\n",
        "    \"\"\"\n",
        "    # Convert inputs to numpy arrays for consistency\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    \n",
        "    # Mean Squared Error (MSE) and Mean Absolute Error (MAE) using sklearn\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "    mape = calculate_mape(scaler=scaler, y_pred_scaled=y_pred)\n",
        "    # Variance and mean of true values\n",
        "    avg_true = np.mean(y_true)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    nrmse = np.sqrt(mse) / avg_true\n",
        "    nmae = mae / avg_true\n",
        "\n",
        "    print(f\"NRMSE (Normalized Root Mean Squared Error): {nrmse:.4f}\")\n",
        "    print(f\"NMAE (Normalized Mean Absolute Error): {nmae:.4f}\")\n",
        "    print(f\"MAPE (Mean Absolute Percentage Error): {mape:.4f}\") \n",
        "    \n",
        "    # Return metrics as a dictionary\n",
        "    return nrmse, nmae, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 638ms/step - loss: 0.1013 - mean_squared_error: 0.1012 - val_loss: 0.0064 - val_mean_squared_error: 0.0078\n",
            "Epoch 2/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 685ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0046 - val_mean_squared_error: 0.0051\n",
            "Epoch 3/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 721ms/step - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0045 - val_mean_squared_error: 0.0050\n",
            "Epoch 4/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 706ms/step - loss: 0.0073 - mean_squared_error: 0.0073 - val_loss: 0.0047 - val_mean_squared_error: 0.0050\n",
            "Epoch 5/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 693ms/step - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0046 - val_mean_squared_error: 0.0050\n",
            "Epoch 6/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 701ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 7/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 701ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0044 - val_mean_squared_error: 0.0048\n",
            "Epoch 8/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 700ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0044 - val_mean_squared_error: 0.0049\n",
            "Epoch 9/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 707ms/step - loss: 0.0068 - mean_squared_error: 0.0068 - val_loss: 0.0044 - val_mean_squared_error: 0.0049\n",
            "Epoch 10/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 711ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0044 - val_mean_squared_error: 0.0049\n",
            "Epoch 11/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 695ms/step - loss: 0.0066 - mean_squared_error: 0.0066 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 12/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 700ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0044 - val_mean_squared_error: 0.0049\n",
            "Epoch 13/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 712ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 14/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 700ms/step - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0044 - val_mean_squared_error: 0.0048\n",
            "Epoch 15/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 699ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0043 - val_mean_squared_error: 0.0048\n",
            "Epoch 16/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 712ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0043 - val_mean_squared_error: 0.0047\n",
            "Epoch 17/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 749ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0044 - val_mean_squared_error: 0.0048\n",
            "Epoch 18/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 752ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0044 - val_mean_squared_error: 0.0048\n",
            "Epoch 19/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 738ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0044 - val_mean_squared_error: 0.0048\n",
            "Epoch 20/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 734ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0043 - val_mean_squared_error: 0.0047\n",
            "Epoch 21/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 716ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0044 - val_mean_squared_error: 0.0048\n",
            "Epoch 22/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 741ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0045 - val_mean_squared_error: 0.0048\n",
            "Epoch 23/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 732ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0043 - val_mean_squared_error: 0.0048\n",
            "Epoch 24/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 737ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0044 - val_mean_squared_error: 0.0048\n",
            "Epoch 25/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 721ms/step - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0044 - val_mean_squared_error: 0.0048\n",
            "Teacher Validation RMSE\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 48ms/step - loss: 0.0021 - mean_squared_error: 0.0021\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.004304586444050074, 0.004317599814385176]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "RANDOM_STATE = 44\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_STATE)\n",
        "keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "def run_teacher_multiv():\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(LSTM(teacher_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(teacher_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Model checkpoint\n",
        "    model_file = multiv_teacher_path\n",
        "\n",
        "    cp = ModelCheckpoint(model_file, save_best_only=True)\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        loss=MeanSquaredError(),\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        metrics=[MeanSquaredError()]\n",
        "    )\n",
        "   \n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[cp, early_stopping]\n",
        "    )\n",
        "\n",
        "run_teacher_multiv()\n",
        "\n",
        "teacher = load_model(multiv_teacher_path)\n",
        "print(\"Teacher Validation RMSE\") \n",
        "teacher.evaluate(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 42ms/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1703\n",
            "NMAE (Normalized Mean Absolute Error): 0.1163\n",
            "MAPE (Mean Absolute Percentage Error): 16.4193\n",
            "Teacher Results: NRMSE = 0.1703, NMAE = 0.1163, MAPE = 16.4193\n"
          ]
        }
      ],
      "source": [
        "teacher = load_model(multiv_teacher_path)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred = teacher.predict(x_test)\n",
        "\n",
        "nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "# Store the results in a dictionary for the teacher\n",
        "teacher_results = {\n",
        "    \"NRMSE\": nrmse,\n",
        "    \"NMAE\": nmae,\n",
        "    \"MAPE\": mape\n",
        "}\n",
        "\n",
        "# Print the results in a single row\n",
        "print(f\"Teacher Results: NRMSE = {teacher_results['NRMSE']:.4f}, NMAE = {teacher_results['NMAE']:.4f}, MAPE = {teacher_results['MAPE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 29ms/step - loss: 0.1986 - mean_squared_error: 0.1985 - val_loss: 0.0150 - val_mean_squared_error: 0.0165\n",
            "Epoch 2/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0463 - mean_squared_error: 0.0463 - val_loss: 0.0174 - val_mean_squared_error: 0.0176\n",
            "Epoch 3/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0327 - mean_squared_error: 0.0327 - val_loss: 0.0124 - val_mean_squared_error: 0.0123\n",
            "Epoch 4/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0263 - mean_squared_error: 0.0263 - val_loss: 0.0119 - val_mean_squared_error: 0.0114\n",
            "Epoch 5/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0106 - val_mean_squared_error: 0.0102\n",
            "Epoch 6/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.0193 - mean_squared_error: 0.0193 - val_loss: 0.0085 - val_mean_squared_error: 0.0084\n",
            "Epoch 7/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0171 - mean_squared_error: 0.0171 - val_loss: 0.0088 - val_mean_squared_error: 0.0086\n",
            "Epoch 8/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.0156 - mean_squared_error: 0.0156 - val_loss: 0.0078 - val_mean_squared_error: 0.0077\n",
            "Epoch 9/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0075 - val_mean_squared_error: 0.0075\n",
            "Epoch 10/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0069 - val_mean_squared_error: 0.0069\n",
            "Epoch 11/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0063 - val_mean_squared_error: 0.0064\n",
            "Epoch 12/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0066 - val_mean_squared_error: 0.0067\n",
            "Epoch 13/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0061 - val_mean_squared_error: 0.0063\n",
            "Epoch 14/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0061 - val_mean_squared_error: 0.0062\n",
            "Epoch 15/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0105 - mean_squared_error: 0.0105 - val_loss: 0.0058 - val_mean_squared_error: 0.0060\n",
            "Epoch 16/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0102 - mean_squared_error: 0.0102 - val_loss: 0.0059 - val_mean_squared_error: 0.0061\n",
            "Epoch 17/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: 0.0097 - mean_squared_error: 0.0097 - val_loss: 0.0059 - val_mean_squared_error: 0.0061\n",
            "Epoch 18/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0057 - val_mean_squared_error: 0.0060\n",
            "Epoch 19/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0095 - mean_squared_error: 0.0095 - val_loss: 0.0056 - val_mean_squared_error: 0.0059\n",
            "Epoch 20/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - val_loss: 0.0055 - val_mean_squared_error: 0.0059\n",
            "Epoch 21/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 0.0057 - val_mean_squared_error: 0.0061\n",
            "Epoch 22/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0058 - val_mean_squared_error: 0.0061\n",
            "Epoch 23/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0059 - val_mean_squared_error: 0.0063\n",
            "Epoch 24/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.0087 - mean_squared_error: 0.0087 - val_loss: 0.0057 - val_mean_squared_error: 0.0061\n",
            "Epoch 25/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.0086 - mean_squared_error: 0.0086 - val_loss: 0.0058 - val_mean_squared_error: 0.0062\n",
            "Student Validation RMSE\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - loss: 0.0037 - mean_squared_error: 0.0037 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.005547190085053444, 0.00555793521925807]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "RANDOM_STATE = 44\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_STATE)\n",
        "keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "def run_student_multiv():\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(LSTM(student_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(student_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Model checkpoint\n",
        "    model_file = multiv_student_path\n",
        "\n",
        "    cp = ModelCheckpoint(model_file, save_best_only=True)\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        loss=MeanSquaredError(),\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        metrics=[MeanSquaredError()]\n",
        "    )\n",
        "   \n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=500,\n",
        "        callbacks=[cp, early_stopping]\n",
        "    )\n",
        "\n",
        "run_student_multiv()\n",
        "\n",
        "student = load_model(multiv_student_path)\n",
        "print(\"Student Validation RMSE\") \n",
        "student.evaluate(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 827us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1944\n",
            "NMAE (Normalized Mean Absolute Error): 0.1472\n",
            "MAPE (Mean Absolute Percentage Error): 23.3606\n",
            "Student Results: NRMSE = 0.1944, NMAE = 0.1472, MAPE = 23.3606\n"
          ]
        }
      ],
      "source": [
        "student = load_model(multiv_student_path)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred = student.predict(x_test)\n",
        "\n",
        "nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "\n",
        "# Store the results in a dictionary\n",
        "student_results = {\n",
        "    \"NRMSE\": nrmse,\n",
        "    \"NMAE\": nmae,\n",
        "    \"MAPE\": mape\n",
        "}\n",
        "# Print the results in a single row\n",
        "print(f\"Student Results: NRMSE = {student_results['NRMSE']:.4f}, NMAE = {student_results['NMAE']:.4f}, MAPE = {student_results['MAPE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.saving import register_keras_serializable\n",
        "\n",
        "@register_keras_serializable()\n",
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "        self._loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        loss,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        loss_threshold,\n",
        "        alpha,\n",
        "        temperature\n",
        "\n",
        "    ):\n",
        "        \"\"\"Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super().compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "        self.loss_threshold = loss_threshold\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'student': self.student.to_json(),\n",
        "            'teacher': self.teacher.to_json()\n",
        "        }\n",
        "\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        student = tf.keras.models.model_from_json(config.pop('student'))\n",
        "        teacher = tf.keras.models.model_from_json(config.pop('teacher'))\n",
        "        return cls(student=student, teacher=teacher, **config)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            y_pred = self.student(x, training=True)\n",
        "            # Compute the loss value\n",
        "            loss = self.compute_loss(x, y, y_pred)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        # Return a dict mapping metric names to current value\n",
        "        results =  {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        results['total loss (train)'] = loss if isinstance(loss, float) else tf.reduce_mean(loss)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass to get student's predictions\n",
        "        y_pred = self.student(x, training=False)\n",
        "\n",
        "        # Compute the validation loss\n",
        "        val_loss = self.compute_loss(x, y, y_pred)\n",
        "\n",
        "        # Manually update the metrics for validation\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        # Collect results for all metrics\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        # Ensure 'val_loss' is properly reduced to a scalar and reported\n",
        "        results['total loss (val)'] = val_loss if isinstance(val_loss, float) else tf.reduce_mean(val_loss)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "\n",
        "    def compute_loss(\n",
        "        # self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "        self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "\n",
        "    ):\n",
        "\n",
        "        mse = MeanSquaredError()\n",
        "\n",
        "        # Compute predictions by the teacher model\n",
        "        teacher_pred = self.teacher(x, training=False)\n",
        "\n",
        "        # Compute the MSE loss between true labels and student predictions\n",
        "        student_loss = mse(y, y_pred)\n",
        "\n",
        "        # Teacher loss is the\n",
        "        temp = self.temperature\n",
        "        # loss = self.alpha * student_loss + (1 - self.alpha) * teacher_loss\n",
        "        loss = self.alpha * student_loss + (1 - self.alpha) * (mse(y_pred/temp, teacher_pred/temp)* (temp ** 2))\n",
        "\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.student(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_multiv_distillation(teacher, alpha, threshold, temperature, file_name, window_size):\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(LSTM(student_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(student_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Create the distiller class\n",
        "    distiller = Distiller(student=model, teacher=teacher)\n",
        "\n",
        "    # Compile the distiller class\n",
        "    distiller.compile(\n",
        "    optimizer = Adam(learning_rate=LEARNING_RATE),\n",
        "    loss = MeanSquaredError(),\n",
        "    metrics = [RootMeanSquaredError()],\n",
        "    student_loss_fn = MeanSquaredError(),\n",
        "    distillation_loss_fn = distiller.compute_loss, #MeanSquaredError(),\n",
        "    loss_threshold = threshold,\n",
        "    alpha=alpha,\n",
        "    temperature=temperature\n",
        "    )\n",
        "\n",
        "    dummy_x = tf.random.normal([1, *((window_size, NUMBER_OF_FEATURES))])  # Replace `input_shape` with the actual shape of your input\n",
        "    _ = distiller(dummy_x) \n",
        "\n",
        "    d_check = ModelCheckpoint(file_name, monitor='root_mean_squared_error',save_best_only=True)\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    distiller.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=EPOCHS, callbacks=[d_check, early_stopping])\n",
        "\n",
        "    distilled_student = load_model(file_name)\n",
        "    # Make predictions using the distilled student model\n",
        "    y_pred = distilled_student.predict(x_val)\n",
        "\n",
        "    # Calculate the root mean squared error (RMSE)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print(\"Distilled Student RMSE:\", rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 51ms/step - root_mean_squared_error: 0.1855 - loss: 0.4852 - total loss (train): 0.0144 - val_loss: 0.5406 - val_total loss (val): 0.0059\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 53ms/step - root_mean_squared_error: 0.0923 - loss: 0.5287 - total loss (train): 0.0042 - val_loss: 0.5535 - val_total loss (val): 0.0031\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 52ms/step - root_mean_squared_error: 0.0860 - loss: 0.5292 - total loss (train): 0.0033 - val_loss: 0.5350 - val_total loss (val): 0.0031\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 58ms/step - root_mean_squared_error: 0.0825 - loss: 0.5290 - total loss (train): 0.0028 - val_loss: 0.5242 - val_total loss (val): 0.0025\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 53ms/step - root_mean_squared_error: 0.0811 - loss: 0.5291 - total loss (train): 0.0026 - val_loss: 0.5011 - val_total loss (val): 0.0031\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 52ms/step - root_mean_squared_error: 0.0796 - loss: 0.5290 - total loss (train): 0.0024 - val_loss: 0.4943 - val_total loss (val): 0.0040\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 58ms/step - root_mean_squared_error: 0.0785 - loss: 0.5291 - total loss (train): 0.0023 - val_loss: 0.4993 - val_total loss (val): 0.0068\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 54ms/step - root_mean_squared_error: 0.0780 - loss: 0.5291 - total loss (train): 0.0022 - val_loss: 0.4947 - val_total loss (val): 0.0090\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 51ms/step - root_mean_squared_error: 0.0770 - loss: 0.5292 - total loss (train): 0.0021 - val_loss: 0.4857 - val_total loss (val): 0.0080\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 48ms/step - root_mean_squared_error: 0.0770 - loss: 0.5292 - total loss (train): 0.0021 - val_loss: 0.4794 - val_total loss (val): 0.0069\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 48ms/step - root_mean_squared_error: 0.0765 - loss: 0.5290 - total loss (train): 0.0021 - val_loss: 0.4822 - val_total loss (val): 0.0086\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 47ms/step - root_mean_squared_error: 0.0763 - loss: 0.5291 - total loss (train): 0.0021 - val_loss: 0.4820 - val_total loss (val): 0.0084\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 46ms/step - root_mean_squared_error: 0.0762 - loss: 0.5290 - total loss (train): 0.0020 - val_loss: 0.4832 - val_total loss (val): 0.0095\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 47ms/step - root_mean_squared_error: 0.0763 - loss: 0.5290 - total loss (train): 0.0020 - val_loss: 0.4837 - val_total loss (val): 0.0119\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 47ms/step - root_mean_squared_error: 0.0760 - loss: 0.5291 - total loss (train): 0.0020 - val_loss: 0.4816 - val_total loss (val): 0.0113\n",
            "\u001b[1m129/291\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 789us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 991us/step\n",
            "Distilled Student RMSE: 0.07079261194396891\n",
            "\u001b[1m133/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 761us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1844\n",
            "NMAE (Normalized Mean Absolute Error): 0.1343\n",
            "MAPE (Mean Absolute Percentage Error): 21.8915\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 50ms/step - root_mean_squared_error: 0.1855 - loss: 0.4843 - total loss (train): 0.0156 - val_loss: 0.5383 - val_total loss (val): 0.0095\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 48ms/step - root_mean_squared_error: 0.0924 - loss: 0.5277 - total loss (train): 0.0054 - val_loss: 0.5475 - val_total loss (val): 0.0052\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 49ms/step - root_mean_squared_error: 0.0861 - loss: 0.5282 - total loss (train): 0.0044 - val_loss: 0.5330 - val_total loss (val): 0.0054\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 48ms/step - root_mean_squared_error: 0.0827 - loss: 0.5280 - total loss (train): 0.0040 - val_loss: 0.5209 - val_total loss (val): 0.0036\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 53ms/step - root_mean_squared_error: 0.0814 - loss: 0.5281 - total loss (train): 0.0038 - val_loss: 0.5051 - val_total loss (val): 0.0032\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 52ms/step - root_mean_squared_error: 0.0799 - loss: 0.5280 - total loss (train): 0.0036 - val_loss: 0.4927 - val_total loss (val): 0.0033\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 53ms/step - root_mean_squared_error: 0.0786 - loss: 0.5280 - total loss (train): 0.0034 - val_loss: 0.4985 - val_total loss (val): 0.0048\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 54ms/step - root_mean_squared_error: 0.0781 - loss: 0.5281 - total loss (train): 0.0033 - val_loss: 0.4897 - val_total loss (val): 0.0058\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 54ms/step - root_mean_squared_error: 0.0772 - loss: 0.5281 - total loss (train): 0.0033 - val_loss: 0.4855 - val_total loss (val): 0.0053\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 53ms/step - root_mean_squared_error: 0.0771 - loss: 0.5282 - total loss (train): 0.0032 - val_loss: 0.4764 - val_total loss (val): 0.0049\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 63ms/step - root_mean_squared_error: 0.0766 - loss: 0.5280 - total loss (train): 0.0032 - val_loss: 0.4722 - val_total loss (val): 0.0047\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 76ms/step - root_mean_squared_error: 0.0764 - loss: 0.5281 - total loss (train): 0.0032 - val_loss: 0.4759 - val_total loss (val): 0.0055\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 74ms/step - root_mean_squared_error: 0.0764 - loss: 0.5281 - total loss (train): 0.0032 - val_loss: 0.4748 - val_total loss (val): 0.0052\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - root_mean_squared_error: 0.0763 - loss: 0.5281 - total loss (train): 0.0031 - val_loss: 0.4718 - val_total loss (val): 0.0072\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - root_mean_squared_error: 0.0761 - loss: 0.5281 - total loss (train): 0.0031 - val_loss: 0.4731 - val_total loss (val): 0.0068\n",
            "Epoch 16/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 68ms/step - root_mean_squared_error: 0.0758 - loss: 0.5282 - total loss (train): 0.0031 - val_loss: 0.4668 - val_total loss (val): 0.0058\n",
            "Epoch 17/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 59ms/step - root_mean_squared_error: 0.0757 - loss: 0.5281 - total loss (train): 0.0031 - val_loss: 0.4664 - val_total loss (val): 0.0056\n",
            "Epoch 18/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 45ms/step - root_mean_squared_error: 0.0757 - loss: 0.5281 - total loss (train): 0.0031 - val_loss: 0.4685 - val_total loss (val): 0.0060\n",
            "Epoch 19/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 45ms/step - root_mean_squared_error: 0.0756 - loss: 0.5280 - total loss (train): 0.0031 - val_loss: 0.4652 - val_total loss (val): 0.0054\n",
            "Epoch 20/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 44ms/step - root_mean_squared_error: 0.0754 - loss: 0.5280 - total loss (train): 0.0031 - val_loss: 0.4679 - val_total loss (val): 0.0057\n",
            "Epoch 21/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 46ms/step - root_mean_squared_error: 0.0753 - loss: 0.5280 - total loss (train): 0.0030 - val_loss: 0.4652 - val_total loss (val): 0.0058\n",
            "Epoch 22/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 47ms/step - root_mean_squared_error: 0.0753 - loss: 0.5280 - total loss (train): 0.0031 - val_loss: 0.4679 - val_total loss (val): 0.0062\n",
            "Epoch 23/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 48ms/step - root_mean_squared_error: 0.0751 - loss: 0.5280 - total loss (train): 0.0030 - val_loss: 0.4717 - val_total loss (val): 0.0059\n",
            "Epoch 24/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 47ms/step - root_mean_squared_error: 0.0751 - loss: 0.5281 - total loss (train): 0.0030 - val_loss: 0.4769 - val_total loss (val): 0.0058\n",
            "Epoch 25/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 44ms/step - root_mean_squared_error: 0.0750 - loss: 0.5280 - total loss (train): 0.0030 - val_loss: 0.4722 - val_total loss (val): 0.0055\n",
            "Epoch 26/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 44ms/step - root_mean_squared_error: 0.0750 - loss: 0.5280 - total loss (train): 0.0030 - val_loss: 0.4754 - val_total loss (val): 0.0075\n",
            "\u001b[1m117/291\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 870us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Distilled Student RMSE: 0.07267399539966408\n",
            "\u001b[1m116/787\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 870us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 957us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1859\n",
            "NMAE (Normalized Mean Absolute Error): 0.1363\n",
            "MAPE (Mean Absolute Percentage Error): 21.7649\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 39ms/step - root_mean_squared_error: 0.1855 - loss: 0.4835 - total loss (train): 0.0167 - val_loss: 0.5382 - val_total loss (val): 0.0127\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 39ms/step - root_mean_squared_error: 0.0927 - loss: 0.5266 - total loss (train): 0.0066 - val_loss: 0.5425 - val_total loss (val): 0.0072\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0864 - loss: 0.5272 - total loss (train): 0.0056 - val_loss: 0.5276 - val_total loss (val): 0.0079\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0831 - loss: 0.5269 - total loss (train): 0.0052 - val_loss: 0.5172 - val_total loss (val): 0.0051\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 39ms/step - root_mean_squared_error: 0.0818 - loss: 0.5270 - total loss (train): 0.0050 - val_loss: 0.5054 - val_total loss (val): 0.0038\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 40ms/step - root_mean_squared_error: 0.0802 - loss: 0.5271 - total loss (train): 0.0047 - val_loss: 0.4901 - val_total loss (val): 0.0034\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0788 - loss: 0.5269 - total loss (train): 0.0046 - val_loss: 0.4977 - val_total loss (val): 0.0031\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0783 - loss: 0.5272 - total loss (train): 0.0045 - val_loss: 0.4905 - val_total loss (val): 0.0032\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0773 - loss: 0.5272 - total loss (train): 0.0044 - val_loss: 0.4864 - val_total loss (val): 0.0035\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 39ms/step - root_mean_squared_error: 0.0773 - loss: 0.5272 - total loss (train): 0.0043 - val_loss: 0.4781 - val_total loss (val): 0.0031\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 39ms/step - root_mean_squared_error: 0.0767 - loss: 0.5270 - total loss (train): 0.0043 - val_loss: 0.4735 - val_total loss (val): 0.0031\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0766 - loss: 0.5270 - total loss (train): 0.0043 - val_loss: 0.4771 - val_total loss (val): 0.0035\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0765 - loss: 0.5271 - total loss (train): 0.0043 - val_loss: 0.4766 - val_total loss (val): 0.0034\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0764 - loss: 0.5271 - total loss (train): 0.0042 - val_loss: 0.4728 - val_total loss (val): 0.0039\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - root_mean_squared_error: 0.0761 - loss: 0.5271 - total loss (train): 0.0042 - val_loss: 0.4781 - val_total loss (val): 0.0041\n",
            "Epoch 16/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - root_mean_squared_error: 0.0758 - loss: 0.5272 - total loss (train): 0.0042 - val_loss: 0.4696 - val_total loss (val): 0.0035\n",
            "Epoch 17/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 38ms/step - root_mean_squared_error: 0.0757 - loss: 0.5270 - total loss (train): 0.0042 - val_loss: 0.4712 - val_total loss (val): 0.0033\n",
            "Epoch 18/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0757 - loss: 0.5270 - total loss (train): 0.0042 - val_loss: 0.4688 - val_total loss (val): 0.0035\n",
            "Epoch 19/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - root_mean_squared_error: 0.0757 - loss: 0.5270 - total loss (train): 0.0042 - val_loss: 0.4653 - val_total loss (val): 0.0035\n",
            "Epoch 20/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0754 - loss: 0.5270 - total loss (train): 0.0041 - val_loss: 0.4707 - val_total loss (val): 0.0038\n",
            "Epoch 21/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0752 - loss: 0.5270 - total loss (train): 0.0041 - val_loss: 0.4661 - val_total loss (val): 0.0035\n",
            "Epoch 22/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 40ms/step - root_mean_squared_error: 0.0753 - loss: 0.5270 - total loss (train): 0.0041 - val_loss: 0.4680 - val_total loss (val): 0.0039\n",
            "Epoch 23/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0750 - loss: 0.5270 - total loss (train): 0.0041 - val_loss: 0.4700 - val_total loss (val): 0.0037\n",
            "Epoch 24/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 38ms/step - root_mean_squared_error: 0.0750 - loss: 0.5271 - total loss (train): 0.0041 - val_loss: 0.4733 - val_total loss (val): 0.0035\n",
            "\u001b[1m116/291\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 874us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Distilled Student RMSE: 0.07477565368032711\n",
            "\u001b[1m119/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 852us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1895\n",
            "NMAE (Normalized Mean Absolute Error): 0.1408\n",
            "MAPE (Mean Absolute Percentage Error): 22.1054\n"
          ]
        }
      ],
      "source": [
        "alphas = [0.3, 0.5, 0.7]\n",
        "temps = [5]\n",
        "threshold = 0\n",
        "\n",
        "# Initialize a 2D list to store RMSE values\n",
        "rmse_matrix = []\n",
        "\n",
        "# Iterate over alphas and temps\n",
        "for alpha in alphas:\n",
        "    row_rmse = []\n",
        "    for temp in temps:\n",
        "\n",
        "        RANDOM_STATE = 44\n",
        "        tf.random.set_seed(RANDOM_STATE)\n",
        "        from numpy.random import seed\n",
        "        seed(RANDOM_STATE)\n",
        "        keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "        multiv_distill_file_name = 'models/girasol/distils/multiv_distil_'+str(alpha)+'_'+str(temp)+'/multiv_distil.keras'\n",
        "        \n",
        "        run_multiv_distillation(teacher, alpha, threshold, temp,  multiv_distill_file_name, MULTIV_TRAINING_WINDOW)\n",
        "        \n",
        "        # Load the model\n",
        "        multiv_distill_file_name = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "        student_kd = load_model(multiv_distill_file_name)\n",
        "\n",
        "        # Make predictions on the scaled test set\n",
        "        y_pred = student_kd.predict(x_test)\n",
        "\n",
        "        nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "        \n",
        "        row_rmse.append(nrmse)\n",
        "\n",
        "    # Append the row of RMSE values to the matrix\n",
        "    rmse_matrix.append(row_rmse)\n",
        "\n",
        "# Convert the list to a NumPy array for plotting\n",
        "rmse_matrix = np.array(rmse_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m117/787\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 869us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 929us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1844\n",
            "NMAE (Normalized Mean Absolute Error): 0.1343\n",
            "MAPE (Mean Absolute Percentage Error): 21.8915\n",
            "\u001b[1m119/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 851us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 928us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1859\n",
            "NMAE (Normalized Mean Absolute Error): 0.1363\n",
            "MAPE (Mean Absolute Percentage Error): 21.7649\n",
            "\u001b[1m109/787\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 955us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 936us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1895\n",
            "NMAE (Normalized Mean Absolute Error): 0.1408\n",
            "MAPE (Mean Absolute Percentage Error): 22.1054\n",
            "Alpha: 0.3, Temp: 5, NRMSE: 0.1844, NMAE: 0.1343, MAPE: 21.8915\n",
            "Alpha: 0.5, Temp: 5, NRMSE: 0.1859, NMAE: 0.1363, MAPE: 21.7649\n",
            "Alpha: 0.7, Temp: 5, NRMSE: 0.1895, NMAE: 0.1408, MAPE: 22.1054\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Example inputs\n",
        "alphas = [0.3, 0.5, 0.7]\n",
        "temps = [5]\n",
        "threshold = 0\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "student_kd_results = []\n",
        "\n",
        "# Iterate over alphas and temps\n",
        "for alpha in alphas:\n",
        "    for temp in temps:\n",
        "        multiv_distill_file_name = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "        \n",
        "        # Load the model\n",
        "        student_kd = load_model(multiv_distill_file_name)\n",
        "\n",
        "        # Make predictions on the scaled test set\n",
        "        y_pred = student_kd.predict(x_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "        \n",
        "        # Add the results to the dictionary\n",
        "        student_kd_results.append({\n",
        "            \"alpha\": alpha,\n",
        "            \"temp\": temp,\n",
        "            \"NRMSE\": nrmse,\n",
        "            \"NMAE\": nmae,\n",
        "            \"MAPE\": mape\n",
        "        })\n",
        "\n",
        "# Print the results\n",
        "for result in student_kd_results:\n",
        "    print(f\"Alpha: {result['alpha']}, Temp: {result['temp']}, NRMSE: {result['NRMSE']:.4f}, \"\n",
        "          f\"NMAE: {result['NMAE']:.4f}, MAPE: {result['MAPE']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Efficiency Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,067,008</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,067,008\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m4,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,213,365</span> (12.26 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,213,365\u001b[0m (12.26 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,071,121</span> (4.09 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,071,121\u001b[0m (4.09 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,142,244</span> (8.17 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,142,244\u001b[0m (8.17 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of parameters: 1071121\n",
            "Model size on disk: 12582.91 KB\n"
          ]
        }
      ],
      "source": [
        "teacher = load_model(multiv_teacher_path)\n",
        "\n",
        "# 1. Print model summary (Layer details and parameter count)\n",
        "print(\"Model Summary:\")\n",
        "teacher.summary()\n",
        "\n",
        "# 2. Get the total number of parameters\n",
        "total_params = teacher.count_params()\n",
        "print(f'\\nTotal number of parameters: {total_params}')\n",
        "\n",
        "# 3. Get the size of the model file on disk\n",
        "model_size = os.path.getsize(multiv_teacher_path) / 1024  #a Convert from bytes to MB\n",
        "print(f'Model size on disk: {model_size:.2f} KB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,600</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,600\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,237</span> (20.46 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,237\u001b[0m (20.46 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,745</span> (6.82 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,745\u001b[0m (6.82 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,492</span> (13.64 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m3,492\u001b[0m (13.64 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of parameters: 1745\n",
            "Model size on disk: 51.17 KB\n"
          ]
        }
      ],
      "source": [
        "student = load_model(multiv_student_path)\n",
        "\n",
        "# 1. Print model summary (Layer details and parameter count)\n",
        "print(\"Model Summary:\")\n",
        "student.summary()\n",
        "\n",
        "# 2. Get the total number of parameters\n",
        "total_params = student.count_params()\n",
        "print(f'\\nTotal number of parameters: {total_params}')\n",
        "\n",
        "# 3. Get the size of the model file on disk\n",
        "model_size = os.path.getsize(multiv_student_path) / 1024  #a Convert from bytes to MB\n",
        "print(f'Model size on disk: {model_size:.2f} KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Error Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Results: NRMSE = 0.1703, NMAE = 0.1163, MAPE = 16.4193\n",
            "Student Results: NRMSE = 0.1944, NMAE = 0.1472, MAPE = 23.3606\n",
            "Student KD Results\n",
            "Alpha: 0.3, Temp: 5, NRMSE: 0.1844, NMAE: 0.1343, MAPE: 21.8915\n",
            "Alpha: 0.5, Temp: 5, NRMSE: 0.1859, NMAE: 0.1363, MAPE: 21.7649\n",
            "Alpha: 0.7, Temp: 5, NRMSE: 0.1895, NMAE: 0.1408, MAPE: 22.1054\n"
          ]
        }
      ],
      "source": [
        "# Print the results in a single row\n",
        "print(f\"Teacher Results: NRMSE = {teacher_results['NRMSE']:.4f}, NMAE = {teacher_results['NMAE']:.4f}, MAPE = {teacher_results['MAPE']:.4f}\")\n",
        "\n",
        "# Print the results in a single row\n",
        "print(f\"Student Results: NRMSE = {student_results['NRMSE']:.4f}, NMAE = {student_results['NMAE']:.4f}, MAPE = {student_results['MAPE']:.4f}\")\n",
        "\n",
        "print('Student KD Results')\n",
        "# Print the results\n",
        "for result in student_kd_results:\n",
        "    print(f\"Alpha: {result['alpha']}, Temp: {result['temp']}, NRMSE: {result['NRMSE']:.4f}, \"\n",
        "          f\"NMAE: {result['NMAE']:.4f}, MAPE: {result['MAPE']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'seaborn'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m alphas \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.7\u001b[39m]\n\u001b[1;32m      4\u001b[0m temps \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m5\u001b[39m]\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
          ]
        }
      ],
      "source": [
        "import seaborn as sns\n",
        "\n",
        "alphas = [0.3, 0.5, 0.7]\n",
        "temps = [5]\n",
        "\n",
        "# Initialize a 2D list to store RMSE values\n",
        "rmse_matrix = []\n",
        "\n",
        "# Iterate over alphas and temps\n",
        "for alpha in alphas:\n",
        "    row_rmse = []\n",
        "    for temp in temps:\n",
        "        # Load the model\n",
        "        multiv_distill_file_name = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "        student_kd = load_model(multiv_distill_file_name)\n",
        "\n",
        "        # Make predictions on the scaled test set\n",
        "        y_pred = student_kd.predict(x_test)\n",
        "\n",
        "        nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "        \n",
        "        row_rmse.append(nrmse)\n",
        "\n",
        "    # Append the row of RMSE values to the matrix\n",
        "    rmse_matrix.append(row_rmse)\n",
        "\n",
        "# Convert the list to a NumPy array for plotting\n",
        "rmse_matrix = np.array(rmse_matrix)\n",
        "\n",
        "# Plot the heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(rmse_matrix, annot=True, fmt='.2f', cmap='viridis', xticklabels=temps, yticklabels=alphas)\n",
        "plt.xlabel('Temperature')\n",
        "plt.ylabel('Alpha')\n",
        "plt.title('Distilled Models on Multivariate Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
