{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2KXKNGKw243x"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "from keras import layers\n",
        "import tensorflow as tf\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bRZKcqpK243y"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error as mse\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.layers import Dense, InputLayer, LSTM, Dropout, Bidirectional, GRU\n",
        "\n",
        "# from keras import ops\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bqALN4gU243z"
      },
      "outputs": [],
      "source": [
        "DC_POWER_INDEX = 0\n",
        "LEARNING_RATE = 0.001\n",
        "RANDOM_STATE = 44\n",
        "START_TIME = '2020-06-07 00:30:00'\n",
        "END_TIME = '2020-06-07 04:00:00'\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "def fix_randomness():\n",
        "    tf.random.set_seed(RANDOM_STATE)\n",
        "\n",
        "    from numpy.random import seed\n",
        "    seed(RANDOM_STATE)\n",
        "    keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "fix_randomness()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MULTIVARIATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "EPOCHS = 500\n",
        "MULTIV_TRAINING_WINDOW = 40\n",
        "lead_time = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creating the model input for multivariate forecasting\n",
        "def df_to_model_input2(df_np, col_index, window_size):\n",
        "    df_np = df_np.to_numpy()\n",
        "    x = []\n",
        "    y = []\n",
        "\n",
        "    for i in range(len(df_np) - window_size - lead_time):\n",
        "        row = [r for r in df_np[i:i+window_size]]\n",
        "        x.append(row)\n",
        "\n",
        "        label = df_np[i+lead_time+window_size][col_index]\n",
        "        y.append(label)\n",
        "\n",
        "    return np.array(x), np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "KVZSHLEo_2v6"
      },
      "outputs": [],
      "source": [
        "multiv_teacher_path = 'models/girasol/multiv_teacher_model.keras'\n",
        "multiv_student_path = 'models/girasol/multiv_student_model.keras'\n",
        "base_model_path = 'models/girasol/base_model.keras'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "train = pd.read_csv('/.../girasol_met/train.csv')\n",
        "test = pd.read_csv('/.../girasol_met/val.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "NUMBER_OF_FEATURES = len(train.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)\n",
        "test = pd.DataFrame(scaler.transform(test), columns=test.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_train_test_val(x, y):\n",
        "    return x[:train_len], y[:train_len], x[train_len:], y[train_len:]\n",
        "\n",
        "x, y = df_to_model_input2(train, 7, MULTIV_TRAINING_WINDOW)\n",
        "\n",
        "ds_len = len(y)\n",
        "train_len = int(0.8*ds_len)\n",
        "\n",
        "x_train, y_train, x_val, y_val = get_train_test_val(x, y)\n",
        "x_test, y_test = df_to_model_input2(test, 7, MULTIV_TRAINING_WINDOW)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((25163, 40, 8), (25163,))"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_test.shape,  y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "teacher_hidden_layer_units, teacher_dense_params = 512, 8\n",
        "student_hidden_layer_units, student_dense_params = 16, 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "def calculate_mape(scaler, y_pred_scaled, target_column_index=-1):\n",
        "\n",
        "    # Create dummy arrays to match the scaler's expected input shape\n",
        "    dummy_data_pred = np.zeros((y_pred_scaled.shape[0], NUMBER_OF_FEATURES))\n",
        "    dummy_data_test = np.zeros((y_test.shape[0], NUMBER_OF_FEATURES))\n",
        "\n",
        "    # Insert the predicted values and y_test into the correct column\n",
        "    dummy_data_pred[:, target_column_index] = y_pred_scaled[:, 0]\n",
        "    dummy_data_test[:, target_column_index] = y_test[:] # it kept that way to be able to modify if needed\n",
        "\n",
        "    # Perform inverse transform to get the unscaled predictions and y_test\n",
        "    unscaled_predictions = scaler.inverse_transform(dummy_data_pred)[:, target_column_index]\n",
        "    y_test_unscaled = scaler.inverse_transform(dummy_data_test)[:, target_column_index]\n",
        "\n",
        "\n",
        "\n",
        "    mape = mean_absolute_percentage_error(y_test_unscaled, unscaled_predictions)*100\n",
        "    return mape\n",
        "\n",
        "def calculate_metrics(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate NMSE, NRMSE, and NMAE normalized by the average of true values.\n",
        "    \n",
        "    Parameters:\n",
        "        y_true (array-like): True values.\n",
        "        y_pred (array-like): Predicted values.\n",
        "        \n",
        "    Returns:\n",
        "        dict: A dictionary containing NMSE, NRMSE, and NMAE.\n",
        "    \"\"\"\n",
        "    # Convert inputs to numpy arrays for consistency\n",
        "    y_true = np.array(y_true)\n",
        "    y_pred = np.array(y_pred)\n",
        "    \n",
        "    # Mean Squared Error (MSE) and Mean Absolute Error (MAE) using sklearn\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "\n",
        "    mape = calculate_mape(scaler=scaler, y_pred_scaled=y_pred)\n",
        "    # Variance and mean of true values\n",
        "    avg_true = np.mean(y_true)\n",
        "    \n",
        "    # Calculate metrics\n",
        "    nrmse = np.sqrt(mse) / avg_true\n",
        "    nmae = mae / avg_true\n",
        "\n",
        "    print(f\"NRMSE (Normalized Root Mean Squared Error): {nrmse:.4f}\")\n",
        "    print(f\"NMAE (Normalized Mean Absolute Error): {nmae:.4f}\")\n",
        "    print(f\"MAPE (Mean Absolute Percentage Error): {mape:.4f}\") \n",
        "    \n",
        "    # Return metrics as a dictionary\n",
        "    return nrmse, nmae, mape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 695ms/step - loss: 0.0563 - mean_squared_error: 0.0563 - val_loss: 0.0066 - val_mean_squared_error: 0.0065\n",
            "Epoch 2/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 710ms/step - loss: 0.0090 - mean_squared_error: 0.0090 - val_loss: 0.0052 - val_mean_squared_error: 0.0055\n",
            "Epoch 3/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 718ms/step - loss: 0.0078 - mean_squared_error: 0.0078 - val_loss: 0.0048 - val_mean_squared_error: 0.0052\n",
            "Epoch 4/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 718ms/step - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0050 - val_mean_squared_error: 0.0053\n",
            "Epoch 5/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 707ms/step - loss: 0.0070 - mean_squared_error: 0.0070 - val_loss: 0.0048 - val_mean_squared_error: 0.0052\n",
            "Epoch 6/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 713ms/step - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0046 - val_mean_squared_error: 0.0050\n",
            "Epoch 7/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 715ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0045 - val_mean_squared_error: 0.0050\n",
            "Epoch 8/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 708ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 9/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 707ms/step - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 10/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 710ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 11/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 723ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 12/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 713ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 13/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 716ms/step - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 14/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 717ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 15/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 717ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0046 - val_mean_squared_error: 0.0050\n",
            "Epoch 16/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 730ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 17/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 717ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 18/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 729ms/step - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Epoch 19/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 735ms/step - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0045 - val_mean_squared_error: 0.0049\n",
            "Teacher Validation RMSE\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 58ms/step - loss: 0.0022 - mean_squared_error: 0.0022\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.004465042147785425, 0.004489721264690161]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "RANDOM_STATE = 44\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_STATE)\n",
        "keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "def run_teacher_multiv():\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(GRU(teacher_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(teacher_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Model checkpoint\n",
        "    model_file = multiv_teacher_path\n",
        "\n",
        "    cp = ModelCheckpoint(model_file, save_best_only=True)\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        loss=MeanSquaredError(),\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        metrics=[MeanSquaredError()]\n",
        "    )\n",
        "   \n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=[cp, early_stopping]\n",
        "    )\n",
        "\n",
        "run_teacher_multiv()\n",
        "\n",
        "teacher = load_model(multiv_teacher_path)\n",
        "print(\"Teacher Validation RMSE\") \n",
        "teacher.evaluate(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 58ms/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1638\n",
            "NMAE (Normalized Mean Absolute Error): 0.1099\n",
            "MAPE (Mean Absolute Percentage Error): 16.0381\n",
            "Teacher Results: NRMSE = 0.1638, NMAE = 0.1099, MAPE = 16.0381\n"
          ]
        }
      ],
      "source": [
        "teacher = load_model(multiv_teacher_path)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred = teacher.predict(x_test)\n",
        "\n",
        "nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "# Store the results in a dictionary for the teacher\n",
        "teacher_results = {\n",
        "    \"NRMSE\": nrmse,\n",
        "    \"NMAE\": nmae,\n",
        "    \"MAPE\": mape\n",
        "}\n",
        "\n",
        "# Print the results in a single row\n",
        "print(f\"Teacher Results: NRMSE = {teacher_results['NRMSE']:.4f}, NMAE = {teacher_results['NMAE']:.4f}, MAPE = {teacher_results['MAPE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.1493 - mean_squared_error: 0.1492 - val_loss: 0.0366 - val_mean_squared_error: 0.0374\n",
            "Epoch 2/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0571 - mean_squared_error: 0.0571 - val_loss: 0.0267 - val_mean_squared_error: 0.0287\n",
            "Epoch 3/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0406 - mean_squared_error: 0.0406 - val_loss: 0.0188 - val_mean_squared_error: 0.0202\n",
            "Epoch 4/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0326 - mean_squared_error: 0.0326 - val_loss: 0.0142 - val_mean_squared_error: 0.0147\n",
            "Epoch 5/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0264 - mean_squared_error: 0.0264 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
            "Epoch 6/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0086 - val_mean_squared_error: 0.0084\n",
            "Epoch 7/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0185 - mean_squared_error: 0.0185 - val_loss: 0.0081 - val_mean_squared_error: 0.0078\n",
            "Epoch 8/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - val_loss: 0.0084 - val_mean_squared_error: 0.0080\n",
            "Epoch 9/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.0148 - mean_squared_error: 0.0148 - val_loss: 0.0074 - val_mean_squared_error: 0.0072\n",
            "Epoch 10/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0065 - val_mean_squared_error: 0.0063\n",
            "Epoch 11/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0061 - val_mean_squared_error: 0.0060\n",
            "Epoch 12/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0119 - mean_squared_error: 0.0119 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 13/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0113 - mean_squared_error: 0.0113 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
            "Epoch 14/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.0107 - mean_squared_error: 0.0107 - val_loss: 0.0053 - val_mean_squared_error: 0.0053\n",
            "Epoch 15/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0053 - val_mean_squared_error: 0.0054\n",
            "Epoch 16/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0058 - val_mean_squared_error: 0.0058\n",
            "Epoch 17/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 18/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0062 - val_mean_squared_error: 0.0062\n",
            "Epoch 19/500\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.0092 - mean_squared_error: 0.0092 - val_loss: 0.0066 - val_mean_squared_error: 0.0066\n",
            "Student Validation RMSE\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0028 - mean_squared_error: 0.0028  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.005269063636660576, 0.00529178511351347]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "RANDOM_STATE = 44\n",
        "tf.random.set_seed(RANDOM_STATE)\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_STATE)\n",
        "keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "def run_student_multiv():\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(GRU(student_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(student_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Model checkpoint\n",
        "    model_file = multiv_student_path\n",
        "\n",
        "    cp = ModelCheckpoint(model_file, save_best_only=True)\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        loss=MeanSquaredError(),\n",
        "        optimizer=Adam(learning_rate=LEARNING_RATE),\n",
        "        metrics=[MeanSquaredError()]\n",
        "    )\n",
        "   \n",
        "    # Train the model\n",
        "    model.fit(\n",
        "        x_train, y_train,\n",
        "        validation_data=(x_val, y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=500,\n",
        "        callbacks=[cp, early_stopping]\n",
        "    )\n",
        "\n",
        "run_student_multiv()\n",
        "\n",
        "student = load_model(multiv_student_path)\n",
        "print(\"Student Validation RMSE\") \n",
        "student.evaluate(x_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1977\n",
            "NMAE (Normalized Mean Absolute Error): 0.1585\n",
            "MAPE (Mean Absolute Percentage Error): 23.9094\n",
            "Student Results: NRMSE = 0.1977, NMAE = 0.1585, MAPE = 23.9094\n"
          ]
        }
      ],
      "source": [
        "student = load_model(multiv_student_path)\n",
        "\n",
        "# Make predictions on the scaled test set\n",
        "y_pred = student.predict(x_test)\n",
        "\n",
        "nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "\n",
        "# Store the results in a dictionary\n",
        "student_results = {\n",
        "    \"NRMSE\": nrmse,\n",
        "    \"NMAE\": nmae,\n",
        "    \"MAPE\": mape\n",
        "}\n",
        "# Print the results in a single row\n",
        "print(f\"Student Results: NRMSE = {student_results['NRMSE']:.4f}, NMAE = {student_results['NMAE']:.4f}, MAPE = {student_results['MAPE']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.saving import register_keras_serializable\n",
        "\n",
        "@register_keras_serializable()\n",
        "class Distiller(keras.Model):\n",
        "    def __init__(self, student, teacher):\n",
        "        super().__init__()\n",
        "        self.teacher = teacher\n",
        "        self.student = student\n",
        "        self._loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
        "\n",
        "    def compile(\n",
        "        self,\n",
        "        optimizer,\n",
        "        loss,\n",
        "        metrics,\n",
        "        student_loss_fn,\n",
        "        distillation_loss_fn,\n",
        "        loss_threshold,\n",
        "        alpha,\n",
        "        temperature\n",
        "\n",
        "    ):\n",
        "        \"\"\"Configure the distiller.\n",
        "\n",
        "        Args:\n",
        "            optimizer: Keras optimizer for the student weights\n",
        "            metrics: Keras metrics for evaluation\n",
        "            student_loss_fn: Loss function of difference between student\n",
        "                predictions and ground-truth\n",
        "            distillation_loss_fn: Loss function of difference between soft\n",
        "                student predictions and soft teacher predictions\n",
        "            alpha: weight to student_loss_fn and 1-alpha to distillation_loss_fn\n",
        "            temperature: Temperature for softening probability distributions.\n",
        "                Larger temperature gives softer distributions.\n",
        "        \"\"\"\n",
        "        super().compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
        "        self.student_loss_fn = student_loss_fn\n",
        "        self.distillation_loss_fn = distillation_loss_fn\n",
        "        self.alpha = alpha\n",
        "        self.temperature = temperature\n",
        "        self.loss_threshold = loss_threshold\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {\n",
        "            'student': self.student.to_json(),\n",
        "            'teacher': self.teacher.to_json()\n",
        "        }\n",
        "\n",
        "        return config\n",
        "\n",
        "    @classmethod\n",
        "    def from_config(cls, config):\n",
        "        student = tf.keras.models.model_from_json(config.pop('student'))\n",
        "        teacher = tf.keras.models.model_from_json(config.pop('teacher'))\n",
        "        return cls(student=student, teacher=teacher, **config)\n",
        "\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Forward pass\n",
        "            y_pred = self.student(x, training=True)\n",
        "            # Compute the loss value\n",
        "            loss = self.compute_loss(x, y, y_pred)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.student.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "\n",
        "        # Update the metrics configured in `compile()`\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        # Return a dict mapping metric names to current value\n",
        "        results =  {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        results['total loss (train)'] = loss if isinstance(loss, float) else tf.reduce_mean(loss)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Forward pass to get student's predictions\n",
        "        y_pred = self.student(x, training=False)\n",
        "\n",
        "        # Compute the validation loss\n",
        "        val_loss = self.compute_loss(x, y, y_pred)\n",
        "\n",
        "        # Manually update the metrics for validation\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "\n",
        "        # Collect results for all metrics\n",
        "        results = {m.name: m.result() for m in self.metrics}\n",
        "\n",
        "        # Ensure 'val_loss' is properly reduced to a scalar and reported\n",
        "        results['total loss (val)'] = val_loss if isinstance(val_loss, float) else tf.reduce_mean(val_loss)\n",
        "\n",
        "        return results\n",
        "\n",
        "\n",
        "\n",
        "    def compute_loss(\n",
        "        # self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "        self, x=None, y=None, y_pred=None, sample_weight=None, allow_empty=False\n",
        "\n",
        "    ):\n",
        "\n",
        "        mse = MeanSquaredError()\n",
        "\n",
        "        # Compute predictions by the teacher model\n",
        "        teacher_pred = self.teacher(x, training=False)\n",
        "\n",
        "        # Compute the MSE loss between true labels and student predictions\n",
        "        student_loss = mse(y, y_pred)\n",
        "\n",
        "        # Teacher loss is the\n",
        "        temp = self.temperature\n",
        "        # loss = self.alpha * student_loss + (1 - self.alpha) * teacher_loss\n",
        "        loss = self.alpha * student_loss + (1 - self.alpha) * (mse(y_pred/temp, teacher_pred/temp)* (temp ** 2))\n",
        "\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.student(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_multiv_distillation(teacher, alpha, threshold, temperature, file_name, window_size):\n",
        "\n",
        "    # Create the model\n",
        "    model = Sequential()\n",
        "    model.add(InputLayer((MULTIV_TRAINING_WINDOW, NUMBER_OF_FEATURES)))\n",
        "    model.add(GRU(student_hidden_layer_units))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(student_dense_params, 'relu'))\n",
        "    model.add(Dense(1, 'linear'))\n",
        "\n",
        "    # Create the distiller class\n",
        "    distiller = Distiller(student=model, teacher=teacher)\n",
        "\n",
        "    # Compile the distiller class\n",
        "    distiller.compile(\n",
        "    optimizer = Adam(learning_rate=LEARNING_RATE),\n",
        "    loss = MeanSquaredError(),\n",
        "    metrics = [RootMeanSquaredError()],\n",
        "    student_loss_fn = MeanSquaredError(),\n",
        "    distillation_loss_fn = distiller.compute_loss, #MeanSquaredError(),\n",
        "    loss_threshold = threshold,\n",
        "    alpha=alpha,\n",
        "    temperature=temperature\n",
        "    )\n",
        "\n",
        "    dummy_x = tf.random.normal([1, *((window_size, NUMBER_OF_FEATURES))])  # Replace `input_shape` with the actual shape of your input\n",
        "    _ = distiller(dummy_x) \n",
        "\n",
        "    d_check = ModelCheckpoint(file_name, monitor='root_mean_squared_error',save_best_only=True)\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss', \n",
        "        patience=5,  # Number of epochs with no improvement after which training will be stopped\n",
        "        restore_best_weights=True  # Restore the weights of the best epoch after stopping\n",
        "    )\n",
        "\n",
        "    distiller.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=EPOCHS, callbacks=[d_check, early_stopping])\n",
        "\n",
        "    distilled_student = load_model(file_name)\n",
        "    # Make predictions using the distilled student model\n",
        "    y_pred = distilled_student.predict(x_val)\n",
        "\n",
        "    # Calculate the root mean squared error (RMSE)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    print(\"Distilled Student RMSE:\", rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 74ms/step - root_mean_squared_error: 0.1959 - loss: 0.5017 - total loss (train): 0.0174 - val_loss: 0.5516 - val_total loss (val): 0.0057\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - root_mean_squared_error: 0.0932 - loss: 0.5298 - total loss (train): 0.0043 - val_loss: 0.5185 - val_total loss (val): 0.0038\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 75ms/step - root_mean_squared_error: 0.0854 - loss: 0.5301 - total loss (train): 0.0032 - val_loss: 0.4758 - val_total loss (val): 0.0038\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 71ms/step - root_mean_squared_error: 0.0822 - loss: 0.5300 - total loss (train): 0.0028 - val_loss: 0.4407 - val_total loss (val): 0.0046\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 70ms/step - root_mean_squared_error: 0.0806 - loss: 0.5298 - total loss (train): 0.0026 - val_loss: 0.4162 - val_total loss (val): 0.0045\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - root_mean_squared_error: 0.0791 - loss: 0.5298 - total loss (train): 0.0024 - val_loss: 0.4058 - val_total loss (val): 0.0048\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 66ms/step - root_mean_squared_error: 0.0779 - loss: 0.5298 - total loss (train): 0.0023 - val_loss: 0.4114 - val_total loss (val): 0.0050\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 66ms/step - root_mean_squared_error: 0.0777 - loss: 0.5296 - total loss (train): 0.0023 - val_loss: 0.3971 - val_total loss (val): 0.0055\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 69ms/step - root_mean_squared_error: 0.0766 - loss: 0.5296 - total loss (train): 0.0022 - val_loss: 0.4100 - val_total loss (val): 0.0056\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 65ms/step - root_mean_squared_error: 0.0771 - loss: 0.5297 - total loss (train): 0.0022 - val_loss: 0.3904 - val_total loss (val): 0.0050\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 62ms/step - root_mean_squared_error: 0.0767 - loss: 0.5296 - total loss (train): 0.0021 - val_loss: 0.3768 - val_total loss (val): 0.0053\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 62ms/step - root_mean_squared_error: 0.0769 - loss: 0.5296 - total loss (train): 0.0021 - val_loss: 0.3778 - val_total loss (val): 0.0058\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 63ms/step - root_mean_squared_error: 0.0762 - loss: 0.5295 - total loss (train): 0.0021 - val_loss: 0.3717 - val_total loss (val): 0.0053\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 64ms/step - root_mean_squared_error: 0.0762 - loss: 0.5296 - total loss (train): 0.0021 - val_loss: 0.3768 - val_total loss (val): 0.0052\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 61ms/step - root_mean_squared_error: 0.0763 - loss: 0.5297 - total loss (train): 0.0021 - val_loss: 0.3712 - val_total loss (val): 0.0052\n",
            "Epoch 16/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 59ms/step - root_mean_squared_error: 0.0759 - loss: 0.5296 - total loss (train): 0.0020 - val_loss: 0.3696 - val_total loss (val): 0.0062\n",
            "Epoch 17/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 58ms/step - root_mean_squared_error: 0.0760 - loss: 0.5296 - total loss (train): 0.0020 - val_loss: 0.3792 - val_total loss (val): 0.0057\n",
            "Epoch 18/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 60ms/step - root_mean_squared_error: 0.0756 - loss: 0.5297 - total loss (train): 0.0020 - val_loss: 0.3722 - val_total loss (val): 0.0059\n",
            "Epoch 19/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 58ms/step - root_mean_squared_error: 0.0760 - loss: 0.5296 - total loss (train): 0.0020 - val_loss: 0.3893 - val_total loss (val): 0.0047\n",
            "Epoch 20/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 55ms/step - root_mean_squared_error: 0.0757 - loss: 0.5297 - total loss (train): 0.0020 - val_loss: 0.3702 - val_total loss (val): 0.0054\n",
            "Epoch 21/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 42ms/step - root_mean_squared_error: 0.0755 - loss: 0.5296 - total loss (train): 0.0020 - val_loss: 0.3738 - val_total loss (val): 0.0056\n",
            "\u001b[1m125/291\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 813us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Distilled Student RMSE: 0.07225228867958118\n",
            "\u001b[1m120/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 844us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 947us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1804\n",
            "NMAE (Normalized Mean Absolute Error): 0.1353\n",
            "MAPE (Mean Absolute Percentage Error): 20.8718\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 39ms/step - root_mean_squared_error: 0.1959 - loss: 0.5008 - total loss (train): 0.0185 - val_loss: 0.5526 - val_total loss (val): 0.0092\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0937 - loss: 0.5286 - total loss (train): 0.0055 - val_loss: 0.5169 - val_total loss (val): 0.0062\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0857 - loss: 0.5289 - total loss (train): 0.0044 - val_loss: 0.4764 - val_total loss (val): 0.0064\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - root_mean_squared_error: 0.0824 - loss: 0.5288 - total loss (train): 0.0040 - val_loss: 0.4524 - val_total loss (val): 0.0080\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0808 - loss: 0.5286 - total loss (train): 0.0037 - val_loss: 0.4212 - val_total loss (val): 0.0072\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0795 - loss: 0.5286 - total loss (train): 0.0036 - val_loss: 0.3989 - val_total loss (val): 0.0084\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0785 - loss: 0.5287 - total loss (train): 0.0034 - val_loss: 0.4150 - val_total loss (val): 0.0087\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0781 - loss: 0.5286 - total loss (train): 0.0034 - val_loss: 0.4068 - val_total loss (val): 0.0099\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0769 - loss: 0.5285 - total loss (train): 0.0033 - val_loss: 0.4173 - val_total loss (val): 0.0099\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0773 - loss: 0.5285 - total loss (train): 0.0033 - val_loss: 0.4018 - val_total loss (val): 0.0092\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0768 - loss: 0.5284 - total loss (train): 0.0033 - val_loss: 0.3907 - val_total loss (val): 0.0092\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0770 - loss: 0.5285 - total loss (train): 0.0033 - val_loss: 0.3992 - val_total loss (val): 0.0096\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0765 - loss: 0.5284 - total loss (train): 0.0032 - val_loss: 0.3798 - val_total loss (val): 0.0096\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0764 - loss: 0.5284 - total loss (train): 0.0032 - val_loss: 0.3897 - val_total loss (val): 0.0091\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0764 - loss: 0.5287 - total loss (train): 0.0032 - val_loss: 0.3881 - val_total loss (val): 0.0080\n",
            "Epoch 16/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0760 - loss: 0.5285 - total loss (train): 0.0032 - val_loss: 0.3810 - val_total loss (val): 0.0094\n",
            "Epoch 17/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0761 - loss: 0.5284 - total loss (train): 0.0031 - val_loss: 0.3890 - val_total loss (val): 0.0092\n",
            "Epoch 18/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 37ms/step - root_mean_squared_error: 0.0757 - loss: 0.5285 - total loss (train): 0.0031 - val_loss: 0.3798 - val_total loss (val): 0.0078\n",
            "Epoch 19/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0760 - loss: 0.5284 - total loss (train): 0.0031 - val_loss: 0.4007 - val_total loss (val): 0.0080\n",
            "Epoch 20/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0757 - loss: 0.5285 - total loss (train): 0.0031 - val_loss: 0.3892 - val_total loss (val): 0.0089\n",
            "Epoch 21/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0754 - loss: 0.5285 - total loss (train): 0.0031 - val_loss: 0.3919 - val_total loss (val): 0.0084\n",
            "Epoch 22/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0753 - loss: 0.5286 - total loss (train): 0.0031 - val_loss: 0.3852 - val_total loss (val): 0.0083\n",
            "Epoch 23/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - root_mean_squared_error: 0.0753 - loss: 0.5284 - total loss (train): 0.0031 - val_loss: 0.3884 - val_total loss (val): 0.0083\n",
            "\u001b[1m123/291\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 826us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Distilled Student RMSE: 0.0729250985182412\n",
            "\u001b[1m122/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 831us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 907us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1767\n",
            "NMAE (Normalized Mean Absolute Error): 0.1292\n",
            "MAPE (Mean Absolute Percentage Error): 20.8544\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 44ms/step - root_mean_squared_error: 0.1961 - loss: 0.4995 - total loss (train): 0.0198 - val_loss: 0.5508 - val_total loss (val): 0.0102\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 42ms/step - root_mean_squared_error: 0.0966 - loss: 0.5273 - total loss (train): 0.0072 - val_loss: 0.5688 - val_total loss (val): 0.0129\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 41ms/step - root_mean_squared_error: 0.0904 - loss: 0.5273 - total loss (train): 0.0063 - val_loss: 0.5565 - val_total loss (val): 0.0134\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 42ms/step - root_mean_squared_error: 0.0851 - loss: 0.5274 - total loss (train): 0.0055 - val_loss: 0.5594 - val_total loss (val): 0.0126\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 42ms/step - root_mean_squared_error: 0.0831 - loss: 0.5273 - total loss (train): 0.0052 - val_loss: 0.5565 - val_total loss (val): 0.0134\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 42ms/step - root_mean_squared_error: 0.0816 - loss: 0.5273 - total loss (train): 0.0050 - val_loss: 0.5551 - val_total loss (val): 0.0115\n",
            "\u001b[1m102/291\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Distilled Student RMSE: 0.06837178977557369\n",
            "\u001b[1m125/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 816us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 896us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1688\n",
            "NMAE (Normalized Mean Absolute Error): 0.1151\n",
            "MAPE (Mean Absolute Percentage Error): 19.0298\n",
            "Epoch 1/500\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:639: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
            "```\n",
            "for metric in self.metrics:\n",
            "    metric.update_state(y, y_pred)\n",
            "```\n",
            "\n",
            "  return self._compiled_metrics_update_state(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 39ms/step - root_mean_squared_error: 0.1960 - loss: 0.4984 - total loss (train): 0.0210 - val_loss: 0.5482 - val_total loss (val): 0.0126\n",
            "Epoch 2/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0981 - loss: 0.5260 - total loss (train): 0.0086 - val_loss: 0.5676 - val_total loss (val): 0.0152\n",
            "Epoch 3/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0905 - loss: 0.5262 - total loss (train): 0.0073 - val_loss: 0.5494 - val_total loss (val): 0.0185\n",
            "Epoch 4/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0850 - loss: 0.5261 - total loss (train): 0.0066 - val_loss: 0.5535 - val_total loss (val): 0.0209\n",
            "Epoch 5/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0833 - loss: 0.5261 - total loss (train): 0.0063 - val_loss: 0.5464 - val_total loss (val): 0.0187\n",
            "Epoch 6/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0821 - loss: 0.5262 - total loss (train): 0.0061 - val_loss: 0.5448 - val_total loss (val): 0.0123\n",
            "Epoch 7/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0802 - loss: 0.5260 - total loss (train): 0.0059 - val_loss: 0.5412 - val_total loss (val): 0.0142\n",
            "Epoch 8/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 40ms/step - root_mean_squared_error: 0.0795 - loss: 0.5261 - total loss (train): 0.0058 - val_loss: 0.5406 - val_total loss (val): 0.0125\n",
            "Epoch 9/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0788 - loss: 0.5262 - total loss (train): 0.0057 - val_loss: 0.5327 - val_total loss (val): 0.0120\n",
            "Epoch 10/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - root_mean_squared_error: 0.0785 - loss: 0.5264 - total loss (train): 0.0056 - val_loss: 0.5203 - val_total loss (val): 0.0153\n",
            "Epoch 11/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0778 - loss: 0.5262 - total loss (train): 0.0055 - val_loss: 0.5184 - val_total loss (val): 0.0154\n",
            "Epoch 12/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0779 - loss: 0.5261 - total loss (train): 0.0055 - val_loss: 0.5067 - val_total loss (val): 0.0142\n",
            "Epoch 13/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0774 - loss: 0.5261 - total loss (train): 0.0055 - val_loss: 0.4988 - val_total loss (val): 0.0153\n",
            "Epoch 14/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0776 - loss: 0.5260 - total loss (train): 0.0055 - val_loss: 0.5030 - val_total loss (val): 0.0138\n",
            "Epoch 15/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0771 - loss: 0.5263 - total loss (train): 0.0054 - val_loss: 0.5016 - val_total loss (val): 0.0145\n",
            "Epoch 16/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0768 - loss: 0.5261 - total loss (train): 0.0054 - val_loss: 0.4923 - val_total loss (val): 0.0148\n",
            "Epoch 17/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 37ms/step - root_mean_squared_error: 0.0769 - loss: 0.5259 - total loss (train): 0.0054 - val_loss: 0.4900 - val_total loss (val): 0.0180\n",
            "Epoch 18/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0764 - loss: 0.5261 - total loss (train): 0.0053 - val_loss: 0.4929 - val_total loss (val): 0.0160\n",
            "Epoch 19/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 38ms/step - root_mean_squared_error: 0.0763 - loss: 0.5262 - total loss (train): 0.0053 - val_loss: 0.4875 - val_total loss (val): 0.0138\n",
            "Epoch 20/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0763 - loss: 0.5261 - total loss (train): 0.0053 - val_loss: 0.4910 - val_total loss (val): 0.0129\n",
            "Epoch 21/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0761 - loss: 0.5261 - total loss (train): 0.0053 - val_loss: 0.4826 - val_total loss (val): 0.0144\n",
            "Epoch 22/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0760 - loss: 0.5262 - total loss (train): 0.0053 - val_loss: 0.4824 - val_total loss (val): 0.0205\n",
            "Epoch 23/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 39ms/step - root_mean_squared_error: 0.0759 - loss: 0.5261 - total loss (train): 0.0053 - val_loss: 0.4790 - val_total loss (val): 0.0191\n",
            "Epoch 24/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0757 - loss: 0.5260 - total loss (train): 0.0052 - val_loss: 0.4699 - val_total loss (val): 0.0142\n",
            "Epoch 25/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 36ms/step - root_mean_squared_error: 0.0758 - loss: 0.5262 - total loss (train): 0.0052 - val_loss: 0.4745 - val_total loss (val): 0.0177\n",
            "Epoch 26/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0755 - loss: 0.5262 - total loss (train): 0.0052 - val_loss: 0.4657 - val_total loss (val): 0.0197\n",
            "Epoch 27/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0752 - loss: 0.5261 - total loss (train): 0.0052 - val_loss: 0.4645 - val_total loss (val): 0.0167\n",
            "Epoch 28/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0752 - loss: 0.5260 - total loss (train): 0.0052 - val_loss: 0.4673 - val_total loss (val): 0.0206\n",
            "Epoch 29/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0753 - loss: 0.5260 - total loss (train): 0.0052 - val_loss: 0.4633 - val_total loss (val): 0.0211\n",
            "Epoch 30/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0749 - loss: 0.5261 - total loss (train): 0.0051 - val_loss: 0.4670 - val_total loss (val): 0.0210\n",
            "Epoch 31/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0751 - loss: 0.5260 - total loss (train): 0.0052 - val_loss: 0.4619 - val_total loss (val): 0.0286\n",
            "Epoch 32/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 36ms/step - root_mean_squared_error: 0.0752 - loss: 0.5260 - total loss (train): 0.0051 - val_loss: 0.4663 - val_total loss (val): 0.0317\n",
            "Epoch 33/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0750 - loss: 0.5262 - total loss (train): 0.0051 - val_loss: 0.4651 - val_total loss (val): 0.0209\n",
            "Epoch 34/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 35ms/step - root_mean_squared_error: 0.0748 - loss: 0.5260 - total loss (train): 0.0051 - val_loss: 0.4607 - val_total loss (val): 0.0219\n",
            "Epoch 35/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 39ms/step - root_mean_squared_error: 0.0748 - loss: 0.5260 - total loss (train): 0.0051 - val_loss: 0.4577 - val_total loss (val): 0.0275\n",
            "Epoch 36/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - root_mean_squared_error: 0.0745 - loss: 0.5261 - total loss (train): 0.0050 - val_loss: 0.4600 - val_total loss (val): 0.0199\n",
            "Epoch 37/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - root_mean_squared_error: 0.0746 - loss: 0.5261 - total loss (train): 0.0051 - val_loss: 0.4646 - val_total loss (val): 0.0221\n",
            "Epoch 38/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - root_mean_squared_error: 0.0745 - loss: 0.5261 - total loss (train): 0.0051 - val_loss: 0.4561 - val_total loss (val): 0.0220\n",
            "Epoch 39/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 38ms/step - root_mean_squared_error: 0.0742 - loss: 0.5260 - total loss (train): 0.0050 - val_loss: 0.4586 - val_total loss (val): 0.0220\n",
            "Epoch 40/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0744 - loss: 0.5261 - total loss (train): 0.0050 - val_loss: 0.4514 - val_total loss (val): 0.0190\n",
            "Epoch 41/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 40ms/step - root_mean_squared_error: 0.0742 - loss: 0.5260 - total loss (train): 0.0050 - val_loss: 0.4552 - val_total loss (val): 0.0232\n",
            "Epoch 42/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0741 - loss: 0.5262 - total loss (train): 0.0050 - val_loss: 0.4597 - val_total loss (val): 0.0203\n",
            "Epoch 43/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 38ms/step - root_mean_squared_error: 0.0736 - loss: 0.5262 - total loss (train): 0.0050 - val_loss: 0.4616 - val_total loss (val): 0.0210\n",
            "Epoch 44/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 37ms/step - root_mean_squared_error: 0.0740 - loss: 0.5261 - total loss (train): 0.0050 - val_loss: 0.4534 - val_total loss (val): 0.0210\n",
            "Epoch 45/500\n",
            "\u001b[1m1162/1162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 38ms/step - root_mean_squared_error: 0.0734 - loss: 0.5262 - total loss (train): 0.0049 - val_loss: 0.4561 - val_total loss (val): 0.0215\n",
            "\u001b[1m121/291\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 835us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Distilled Student RMSE: 0.06837722226837102\n",
            "\u001b[1m126/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 808us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1705\n",
            "NMAE (Normalized Mean Absolute Error): 0.1171\n",
            "MAPE (Mean Absolute Percentage Error): 19.7833\n"
          ]
        }
      ],
      "source": [
        "alphas = [0.3, 0.5, 0.7, 0.9]\n",
        "temps = [5]\n",
        "threshold = 0\n",
        "\n",
        "# Initialize a 2D list to store RMSE values\n",
        "rmse_matrix = []\n",
        "\n",
        "# Iterate over alphas and temps\n",
        "for alpha in alphas:\n",
        "    row_rmse = []\n",
        "    for temp in temps:\n",
        "\n",
        "        RANDOM_STATE = 44\n",
        "        tf.random.set_seed(RANDOM_STATE)\n",
        "        from numpy.random import seed\n",
        "        seed(RANDOM_STATE)\n",
        "        keras.utils.set_random_seed(RANDOM_STATE)\n",
        "\n",
        "        multiv_distill_file_name = 'models/girasol/distils/multiv_distil_'+str(alpha)+'_'+str(temp)+'/multiv_distil.keras'\n",
        "        \n",
        "        run_multiv_distillation(teacher, alpha, threshold, temp,  multiv_distill_file_name, MULTIV_TRAINING_WINDOW)\n",
        "        \n",
        "        # Load the model\n",
        "        multiv_distill_file_name = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "        student_kd = load_model(multiv_distill_file_name)\n",
        "\n",
        "        # Make predictions on the scaled test set\n",
        "        y_pred = student_kd.predict(x_test)\n",
        "\n",
        "        nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "        \n",
        "        row_rmse.append(nrmse)\n",
        "\n",
        "    # Append the row of RMSE values to the matrix\n",
        "    rmse_matrix.append(row_rmse)\n",
        "\n",
        "# Convert the list to a NumPy array for plotting\n",
        "rmse_matrix = np.array(rmse_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m125/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 815us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 899us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1804\n",
            "NMAE (Normalized Mean Absolute Error): 0.1353\n",
            "MAPE (Mean Absolute Percentage Error): 20.8718\n",
            "\u001b[1m127/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 802us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 894us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1767\n",
            "NMAE (Normalized Mean Absolute Error): 0.1292\n",
            "MAPE (Mean Absolute Percentage Error): 20.8544\n",
            "\u001b[1m124/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 820us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 898us/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1688\n",
            "NMAE (Normalized Mean Absolute Error): 0.1151\n",
            "MAPE (Mean Absolute Percentage Error): 19.0298\n",
            "\u001b[1m125/787\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 814us/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m787/787\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step\n",
            "NRMSE (Normalized Root Mean Squared Error): 0.1705\n",
            "NMAE (Normalized Mean Absolute Error): 0.1171\n",
            "MAPE (Mean Absolute Percentage Error): 19.7833\n",
            "Alpha: 0.3, Temp: 5, NRMSE: 0.1804, NMAE: 0.1353, MAPE: 20.8718\n",
            "Alpha: 0.5, Temp: 5, NRMSE: 0.1767, NMAE: 0.1292, MAPE: 20.8544\n",
            "Alpha: 0.7, Temp: 5, NRMSE: 0.1688, NMAE: 0.1151, MAPE: 19.0298\n",
            "Alpha: 0.9, Temp: 5, NRMSE: 0.1705, NMAE: 0.1171, MAPE: 19.7833\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Example inputs\n",
        "alphas = [0.3, 0.5, 0.7, 0.9]\n",
        "temps = [5]\n",
        "threshold = 0\n",
        "\n",
        "# Initialize a dictionary to store results\n",
        "student_kd_results = []\n",
        "\n",
        "# Iterate over alphas and temps\n",
        "for alpha in alphas:\n",
        "    for temp in temps:\n",
        "        multiv_distill_file_name = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "        \n",
        "        # Load the model\n",
        "        student_kd = load_model(multiv_distill_file_name)\n",
        "\n",
        "        # Make predictions on the scaled test set\n",
        "        y_pred = student_kd.predict(x_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        nrmse, nmae, mape = calculate_metrics(y_test, y_pred)\n",
        "        \n",
        "        # Add the results to the dictionary\n",
        "        student_kd_results.append({\n",
        "            \"alpha\": alpha,\n",
        "            \"temp\": temp,\n",
        "            \"NRMSE\": nrmse,\n",
        "            \"NMAE\": nmae,\n",
        "            \"MAPE\": mape\n",
        "        })\n",
        "\n",
        "# Print the results\n",
        "for result in student_kd_results:\n",
        "    print(f\"Alpha: {result['alpha']}, Temp: {result['temp']}, NRMSE: {result['NRMSE']:.4f}, \"\n",
        "          f\"NMAE: {result['NMAE']:.4f}, MAPE: {result['MAPE']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "RESULTS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Efficiency Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">801,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,104</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m801,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │         \u001b[38;5;34m4,104\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,417,717</span> (9.22 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,417,717\u001b[0m (9.22 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">805,905</span> (3.07 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m805,905\u001b[0m (3.07 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,611,812</span> (6.15 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,611,812\u001b[0m (6.15 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of parameters: 805905\n",
            "Model size on disk: 9474.91 KB\n"
          ]
        }
      ],
      "source": [
        "teacher = load_model(multiv_teacher_path)\n",
        "\n",
        "# 1. Print model summary (Layer details and parameter count)\n",
        "print(\"Model Summary:\")\n",
        "teacher.summary()\n",
        "\n",
        "# 2. Get the total number of parameters\n",
        "total_params = teacher.count_params()\n",
        "print(f'\\nTotal number of parameters: {total_params}')\n",
        "\n",
        "# 3. Get the size of the model file on disk\n",
        "model_size = os.path.getsize(multiv_teacher_path) / 1024  #a Convert from bytes to MB\n",
        "print(f'Model size on disk: {model_size:.2f} KB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model Summary:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,248</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">136</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ gru_1 (\u001b[38;5;33mGRU\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,248\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)              │           \u001b[38;5;34m136\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m9\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,181</span> (16.34 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,181\u001b[0m (16.34 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,393</span> (5.44 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,393\u001b[0m (5.44 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,788</span> (10.89 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,788\u001b[0m (10.89 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Total number of parameters: 1393\n",
            "Model size on disk: 47.04 KB\n"
          ]
        }
      ],
      "source": [
        "student = load_model(multiv_student_path)\n",
        "\n",
        "# 1. Print model summary (Layer details and parameter count)\n",
        "print(\"Model Summary:\")\n",
        "student.summary()\n",
        "\n",
        "# 2. Get the total number of parameters\n",
        "total_params = student.count_params()\n",
        "print(f'\\nTotal number of parameters: {total_params}')\n",
        "\n",
        "# 3. Get the size of the model file on disk\n",
        "model_size = os.path.getsize(multiv_student_path) / 1024  #a Convert from bytes to MB\n",
        "print(f'Model size on disk: {model_size:.2f} KB')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Error Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Teacher Results: NRMSE = 0.1638, NMAE = 0.1099, MAPE = 16.0381\n",
            "Student Results: NRMSE = 0.1977, NMAE = 0.1585, MAPE = 23.9094\n",
            "Student KD Results\n",
            "Alpha: 0.3, Temp: 5, NRMSE: 0.1804, NMAE: 0.1353, MAPE: 20.8718\n",
            "Alpha: 0.5, Temp: 5, NRMSE: 0.1767, NMAE: 0.1292, MAPE: 20.8544\n",
            "Alpha: 0.7, Temp: 5, NRMSE: 0.1688, NMAE: 0.1151, MAPE: 19.0298\n",
            "Alpha: 0.9, Temp: 5, NRMSE: 0.1705, NMAE: 0.1171, MAPE: 19.7833\n"
          ]
        }
      ],
      "source": [
        "# Print the results in a single row\n",
        "print(f\"Teacher Results: NRMSE = {teacher_results['NRMSE']:.4f}, NMAE = {teacher_results['NMAE']:.4f}, MAPE = {teacher_results['MAPE']:.4f}\")\n",
        "\n",
        "# Print the results in a single row\n",
        "print(f\"Student Results: NRMSE = {student_results['NRMSE']:.4f}, NMAE = {student_results['NMAE']:.4f}, MAPE = {student_results['MAPE']:.4f}\")\n",
        "\n",
        "print('Student KD Results')\n",
        "# Print the results\n",
        "for result in student_kd_results:\n",
        "    print(f\"Alpha: {result['alpha']}, Temp: {result['temp']}, NRMSE: {result['NRMSE']:.4f}, \"\n",
        "          f\"NMAE: {result['NMAE']:.4f}, MAPE: {result['MAPE']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Forecasting Skill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m  4/291\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7s\u001b[0m 25ms/step "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/ifranrahmannijhum/miniforge3/envs/tf/lib/python3.12/site-packages/keras/src/saving/serialization_lib.py:734: UserWarning: `compile()` was not called as part of model loading because the model's `compile()` method is custom. All subclassed Models that have `compile()` overridden should also override `get_compile_config()` and `compile_from_config(config)`. Alternatively, you can call `compile()` manually after loading.\n",
            "  instance.compile_from_config(compile_config)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 26ms/step\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "\u001b[1m  1/291\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00\u001b[0m 209ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1736791091.874953  144074 service.cc:148] XLA service 0x309c261f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1736791091.875098  144074 service.cc:156]   StreamExecutor device (0): Host, Default Version\n",
            "2025-01-13 17:58:11.898303: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1736791092.051277  144074 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 303us/step\n",
            "\u001b[1m291/291\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
            "Model               RMSE      Forecasting Skill (%)    \n",
            "-------------------------------------------------------\n",
            "Multiv Teacher      0.0668    1.88                     \n",
            "Multiv Student      0.0726    -6.59                    \n",
            "Base Model          0.0681    --                       \n",
            "Distilled Student   0.0684    -0.41                    \n"
          ]
        }
      ],
      "source": [
        "alpha = 0.9\n",
        "temp = 5\n",
        "distilled_student_path = f'models/girasol/distils/multiv_distil_{alpha}_{temp}/multiv_distil.keras'\n",
        "\n",
        "# Load models\n",
        "multiv_teacher = load_model(multiv_teacher_path)\n",
        "multiv_student = load_model(multiv_student_path)\n",
        "base_model = load_model(base_model_path)\n",
        "distilled_student = load_model(distilled_student_path)\n",
        "\n",
        "# Function to calculate RMSE\n",
        "def calculate_rmse(model, x_val, y_val):\n",
        "    y_pred = model.predict(x_val)\n",
        "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "    return rmse\n",
        "\n",
        "# Calculate RMSE for all models\n",
        "rmse_multiv_teacher = calculate_rmse(multiv_teacher, x_val, y_val)\n",
        "rmse_multiv_student = calculate_rmse(multiv_student, x_val, y_val)\n",
        "rmse_base_model = calculate_rmse(base_model, x_val, y_val)\n",
        "rmse_distilled_student = calculate_rmse(distilled_student, x_val, y_val)\n",
        "\n",
        "# Calculate forecasting skill scores relative to the base model\n",
        "def calculate_skill_score(base_rmse, model_rmse):\n",
        "    return 100 * (1 - model_rmse / base_rmse)\n",
        "\n",
        "skill_teacher = calculate_skill_score(rmse_base_model, rmse_multiv_teacher)\n",
        "skill_student = calculate_skill_score(rmse_base_model, rmse_multiv_student)\n",
        "skill_distilled = calculate_skill_score(rmse_base_model, rmse_distilled_student)\n",
        "\n",
        "# Print RMSE and skill scores in a clear format\n",
        "print(f\"{'Model':<20}{'RMSE':<10}{'Forecasting Skill (%)':<25}\")\n",
        "print(f\"{'-'*55}\")\n",
        "print(f\"{'Multiv Teacher':<20}{rmse_multiv_teacher:<10.4f}{skill_teacher:<25.2f}\")\n",
        "print(f\"{'Multiv Student':<20}{rmse_multiv_student:<10.4f}{skill_student:<25.2f}\")\n",
        "print(f\"{'Base Model':<20}{rmse_base_model:<10.4f}{'--':<25}\")\n",
        "print(f\"{'Distilled Student':<20}{rmse_distilled_student:<10.4f}{skill_distilled:<25.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
